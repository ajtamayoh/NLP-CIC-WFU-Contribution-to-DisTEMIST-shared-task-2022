{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajtamayoh/NLP-CIC-WFU-Contribution-to-DisTEMIST-shared-task-2022/blob/main/Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP-CIC-WFU contribution to DisTEMIST 2022 sub-track 1 entities\n",
        "\n",
        "Here you are the source code for the paper:\n",
        "\n",
        "### mBERT and Simple Post-Processing: A Baseline for Disease Mention Detection in Spanish\n",
        "\n",
        "Authors:\n",
        "\n",
        "Antonio Tamayo (ajtamayo2019@ipn.cic.mx, ajtamayoh@gmail.com)\n",
        "\n",
        "Diego A. Burgos (burgosda@wfu.edu)\n",
        "\n",
        "Alexander Gelbulkh (gelbukh@gelbukh.com)\n",
        "\n",
        "For bugs or questions related to the code, do not hesitate to contact us (Antonio Tamayo: ajtamayoh@gmail.com)\n",
        "\n",
        "If you use this code please cite our work:\n",
        "\n"
      ],
      "metadata": {
        "id": "Nml9hXt1NHXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements\n",
        "\n",
        "To run this code you need to download the dataset (two folders: training and test_background) at: https://drive.google.com/drive/folders/1qJQQHdEkm6YMN-1KRUPfBx8lFQKUZK5Z?usp=sharing\n",
        "\n",
        "Then, you must create a folder called \"Datasets\" in the root of your Google Drive and load there both folders previously downloaded."
      ],
      "metadata": {
        "id": "6S9L_KErP3yM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About the infrastructure"
      ],
      "metadata": {
        "id": "3gGu8XvkQuHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "9YCD8Yn8QvCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "PDijHzOMQzwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to Google drive"
      ],
      "metadata": {
        "id": "U64pk_flQ-nw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgzIfAnfaDR1",
        "outputId": "a89ad810-0b40-4284-8844-f51958c2e8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1ncKARiLoRQ"
      },
      "source": [
        "## Exploring & Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZaPi7EMLrz8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5PLlHg0aLtGp",
        "outputId": "0875d82b-66ca-4705-fd0d-002f2f49cb2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       filename mark       label  off0  off1  \\\n",
              "0  es-S0210-56912007000900007-3   T1  ENFERMEDAD   164   166   \n",
              "1  es-S0210-56912007000900007-3   T2  ENFERMEDAD   362   376   \n",
              "2  es-S0210-56912007000900007-3   T3  ENFERMEDAD   575   590   \n",
              "3  es-S0210-56912007000900007-3   T4  ENFERMEDAD   715   733   \n",
              "4  es-S0210-56912007000900007-3   T5  ENFERMEDAD  1402  1459   \n",
              "\n",
              "                                                span  \n",
              "0                                                 DM  \n",
              "1                                     deshidratación  \n",
              "2                                    hiperamilasemia  \n",
              "3                                 pancreatitis aguda  \n",
              "4  formación polipoidea sésil situada junto al es...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2666b0e-b684-4b6b-ac9e-6442af588717\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>mark</th>\n",
              "      <th>label</th>\n",
              "      <th>off0</th>\n",
              "      <th>off1</th>\n",
              "      <th>span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>es-S0210-56912007000900007-3</td>\n",
              "      <td>T1</td>\n",
              "      <td>ENFERMEDAD</td>\n",
              "      <td>164</td>\n",
              "      <td>166</td>\n",
              "      <td>DM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>es-S0210-56912007000900007-3</td>\n",
              "      <td>T2</td>\n",
              "      <td>ENFERMEDAD</td>\n",
              "      <td>362</td>\n",
              "      <td>376</td>\n",
              "      <td>deshidratación</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>es-S0210-56912007000900007-3</td>\n",
              "      <td>T3</td>\n",
              "      <td>ENFERMEDAD</td>\n",
              "      <td>575</td>\n",
              "      <td>590</td>\n",
              "      <td>hiperamilasemia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>es-S0210-56912007000900007-3</td>\n",
              "      <td>T4</td>\n",
              "      <td>ENFERMEDAD</td>\n",
              "      <td>715</td>\n",
              "      <td>733</td>\n",
              "      <td>pancreatitis aguda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>es-S0210-56912007000900007-3</td>\n",
              "      <td>T5</td>\n",
              "      <td>ENFERMEDAD</td>\n",
              "      <td>1402</td>\n",
              "      <td>1459</td>\n",
              "      <td>formación polipoidea sésil situada junto al es...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2666b0e-b684-4b6b-ac9e-6442af588717')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2666b0e-b684-4b6b-ac9e-6442af588717 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2666b0e-b684-4b6b-ac9e-6442af588717');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "distemist_track_1_training = pd.read_csv(\"/content/drive/MyDrive/Datasets/training/subtrack1_entities/distemist_subtrack1_training_mentions.tsv\", delimiter=\"\\t\")\n",
        "distemist_track_1_training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW058gNCnxMD"
      },
      "outputs": [],
      "source": [
        "list_off0 = list(distemist_track_1_training['off0'])\n",
        "list_off1 = list(distemist_track_1_training['off1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnhX_oQ5CJfh"
      },
      "outputs": [],
      "source": [
        "text_files_path = \"/content/drive/MyDrive/Datasets/training/text_files\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNIun4SYCzP5",
        "outputId": "c4589040-9cba-4c5a-bf5d-87d298ad3fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mujer de 74 años que ingresó en el hospital por obnubilación y anuria tras presentar durante 5 días dolor abdominal y vómitos. Entre sus antecedentes destacaba una DM tratada con metformina (850 mg/8 h) y glibenclamida. La presión arterial era de 105/60 mmHg, la frecuencia cardíaca de 155 latidos/minuto y la temperatura de 36,7º C. En la exploración destacaba deshidratación intensa, desorientación, respiración de Kussmaul, dolor abdominal con peristaltismo débil y ausencia de defensa abdominal. La tabla 2 muestra los principales datos analíticos, destacando además una hiperamilasemia de 2.605 U/l. Una tomografía computarizada abdominal descubrió un aumento del tamaño de la cabeza del páncreas sugerente de pancreatitis aguda. Tras suspender la administración de metformina, la paciente fue intubada orotraquealmente y conectada a un respirador mecánico. También recibió tratamiento a base de fluidos con suplementos de potasio, noradrenalina, bicarbonato, insulina, amiodarona, imipenen y furosemida. Al segundo día de ingreso, tras administrar 750 mEq de bicarbonato y 140 mEq de potasio, se normalizó el equilibrio ácido-básico (pH 7,41 y bicarbonato 20 mEq/l) e hidroelectrolítico (sodio 147 mEq/l, potasio 3,5 mEq/l) y la creatinina descendió a 5,5 mg/dl. Al tercer día de ingreso, por la presencia de deposiciones mucosas repetidas, se realizó una colonoscopia que puso de manifiesto una formación polipoidea sésil situada junto al esfínter anal y de 14 cm de longitud. La muestra endoscópica fue informada como adenoma velloso de recto. Al séptimo día de ingreso la enferma fue extubada, y dos días más tarde fue trasladada a planta para extirpación del adenoma\n",
            "\n"
          ]
        }
      ],
      "source": [
        "f = open(text_files_path + \"/\" + distemist_track_1_training.iloc[1,0] + \".txt\", \"r\", encoding=\"UTF-8\")\n",
        "for l in f:\n",
        "  print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhs3W80KM7ZG"
      },
      "outputs": [],
      "source": [
        "#Clinical cases\n",
        "HCs = {}\n",
        "for fname in distemist_track_1_training[\"filename\"]:\n",
        "  with open(text_files_path + \"/\" + fname + \".txt\", \"r\", encoding=\"UTF-8\") as f:\n",
        "    HCs.update({fname: f.read()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPDGRBTdLw_W",
        "outputId": "4faaf637-06ae-4d69-9c6a-c84c0de946cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "len(HCs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOVeEVPjLIM5"
      },
      "outputs": [],
      "source": [
        "#This code cell is optional. Uncomment it if you want to create a small development partition\n",
        "'''\n",
        "dev_files = [\"es-S1130-14732006000500005-1\", \"es-S1130-14732005000200003-1\", \"es-S1130-05582014000200008-1\", \"es-S0365-66912010000600004-1\", \"es-S0212-71992004000600005-1\", \"es-S0211-57352011000100008-1\", \"es-S0210-48062009000600016-1\", \"es-S0004-06142009000200008-1\", \"es-S0004-06142007000600016-2\"]\n",
        "#Se descomenta para tener un dataset de development y observar las métricas con el script de la competencia\n",
        "for f in dev_files:\n",
        "  HCs.pop(f)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0xkvhzkL0g9",
        "outputId": "3efbd171-0bfd-4585-dfc4-de8055e77037"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "len(HCs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D_CPkKjsCzz"
      },
      "outputs": [],
      "source": [
        "#Diseases\n",
        "ENF = {}\n",
        "enfermedades = []\n",
        "fn = distemist_track_1_training[\"filename\"][0]\n",
        "for fname, enf in zip(distemist_track_1_training[\"filename\"], distemist_track_1_training[\"span\"]):\n",
        "    if fname!=fn:\n",
        "      enfermedades = []\n",
        "    enfermedades.append(enf)\n",
        "    ENF.update({fname: enfermedades})\n",
        "    fn = fname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-aDUgrHULAi",
        "outputId": "986e7c95-40c6-4a6b-a199-43ef3634ae27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "len(ENF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMYj6Vo6MNzB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0f574b6f-1682-4f0a-b1da-70ef7f7ad0a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Se descomenta para tener un dataset de development y observar las métricas con el script de la competencia\\nfor f in dev_files:\\n  ENF.pop(f)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "#This code cell is optional. Uncomment it if you want to create a small development partition. This works together with the cell above with a similar comment.\n",
        "'''\n",
        "#Se descomenta para tener un dataset de development y observar las métricas con el script de la competencia\n",
        "for f in dev_files:\n",
        "  ENF.pop(f)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4xf4L3nMQDK",
        "outputId": "b5df78b7-7dfd-4eb9-e746-60a4a6ecc470"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "len(ENF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "tNRlMovPn5mi",
        "outputId": "d9a3356c-d5c8-47e9-acbc-5323ef49bb84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Varón de tres años y medio afecto de daño neurológico grave secundario a accidente cerebrovascular agudo (ACV) isquémico perinatal. Acude a consulta con su madre, que nos relata un llanto inusual desde hace unas semanas y la sospecha de que el niño tiene dolor en las manos. Asimismo nos comenta que el niño recibe desde hace unas semanas tratamiento con esteroides orales, pues en el seguimiento de su daño neurológico, al consultar por los síntomas del aparato locomotor, se sospechó artritis crónica idiopática con radiografía normal de manos y muñecas.\\nEs hijo único de padres no consanguíneos. El padre tiende un problema óseo en las muñecas desde la infancia; recuerda haber padecido dolores en las muñecas cuando era niño y nos refiere que no tiene los huesos de las muñecas, que conserva movilidad normal y que no le supone problemas en su profesión de conductor de coches.\\nLa exploración física del niño está condicionada por su daño neurológico (emite gritos, sin lenguaje de otro tipo y escucha y atiende cuando se le habla, sonriendo con las caricias); no es capaz de deambulación sin ayuda; una hemiplejia izquierda derivada de su ACV perinatal y los datos propios de espasticidad. La somatometría recoge un perímetro craneal de 46 cm (< P3), una longitud de 104 cm (P25-50) y un peso de 16,5 Kg (P50). Los valores de presión arterial son normales (111/66 mmHg). No se aprecian rasgos dismórficos. Llama la atención el intento repetido del niño de morderse su muñeca derecha. No hay signos inflamatorios y se expresa con gemidos ante la movilización repetida de esa muñeca derecha. No apreciamos afectación de otras articulaciones.\\nEl padre tiene una talla de 180 cm, pero su envergadura está reducida a 164 cm. Su mano mide 18,7 cm de longitud (resulta acortada 4 cm para su estatura) con un tercer dedo de 8,3 cm (normal). La radiografía paterna muestra ausencia bilateral del carpo.\\n\\nLa radiografía del niño muestra lesiones carpales compatibles con osteólisis carpiana y lesiones en el escafoides tarsiano unilaterales.\\n\\nSolicitamos consulta al servicio de genética donde se estudia y se confirma el diagnóstico de osteólisis multicéntrica carpotarsal de transmisión autosómica dominante sin nefropatía.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "HCs[\"es-S1139-76322015000300009-1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjmYjm_u7LBl",
        "outputId": "851a82ee-1057-4530-ee79-2943202062f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DM',\n",
              " 'deshidratación',\n",
              " 'hiperamilasemia',\n",
              " 'pancreatitis aguda',\n",
              " 'formación polipoidea sésil situada junto al esfínter anal',\n",
              " 'adenoma velloso de recto',\n",
              " 'adenoma']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "ENF[\"es-S0210-56912007000900007-3\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization using SpaCy"
      ],
      "metadata": {
        "id": "4ZSJ6gatRc9r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocmTmRkiLtJM"
      },
      "outputs": [],
      "source": [
        "from spacy.lang.es import Spanish\n",
        "nlp = Spanish()\n",
        "# Create a Tokenizer with the default settings for Spanish\n",
        "# including punctuation rules and exceptions\n",
        "tokenizer_spacy = nlp.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orQHlLHJM7b3"
      },
      "outputs": [],
      "source": [
        "HCs_tokenized = []\n",
        "for hc in HCs:\n",
        "    hl = []\n",
        "    tokens = tokenizer_spacy(HCs[hc])\n",
        "    #tokens = HCs[hc].split(\" \") #The simplest option. It was not used in our work.\n",
        "    for t in tokens:\n",
        "        hl.append(str(t))\n",
        "    HCs_tokenized.append(hl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rClFCgxnM7e4",
        "outputId": "353aa26b-1745-4e1a-a050-f2dc1e8e6479"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "len(HCs_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0v803fyUFSM"
      },
      "outputs": [],
      "source": [
        "#HCs_tokenized[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xE2NudYNHey"
      },
      "outputs": [],
      "source": [
        "Ent_tokenized = []\n",
        "for enf in ENF:\n",
        "    Tks = []\n",
        "    for e in ENF[enf]:\n",
        "      sl = []\n",
        "      tokens = tokenizer_spacy(e)\n",
        "      #tokens = e.split(\" \")\n",
        "      for t in tokens:\n",
        "          sl.append(str(t))\n",
        "      Tks.append(sl)\n",
        "    Ent_tokenized.append(Tks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMuPfY-XNHh4",
        "outputId": "6df43556-b2a7-43fa-fd71-2126d197d5e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "len(Ent_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR--IobbNHj6",
        "outputId": "45e39efa-3025-4ade-c604-7e6356364dcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['DM'],\n",
              " ['deshidratación'],\n",
              " ['hiperamilasemia'],\n",
              " ['pancreatitis', 'aguda'],\n",
              " ['formación',\n",
              "  'polipoidea',\n",
              "  'sésil',\n",
              "  'situada',\n",
              "  'junto',\n",
              "  'al',\n",
              "  'esfínter',\n",
              "  'anal'],\n",
              " ['adenoma', 'velloso', 'de', 'recto'],\n",
              " ['adenoma']]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "Ent_tokenized[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQu4uagdNePZ"
      },
      "source": [
        "## Tagging Data with BIO scheme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKy-FSGdiWhY"
      },
      "outputs": [],
      "source": [
        "def find_idx(list_to_check, item_to_find):\n",
        "    indices = []\n",
        "    for idx, value in enumerate(list_to_check):\n",
        "        if value == item_to_find:\n",
        "            indices.append(idx)\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsuGnvZMNYX2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "labels_tokenized = []\n",
        "idx =-1\n",
        "for hct, et in zip(HCs_tokenized, Ent_tokenized):\n",
        "    idx+=1\n",
        "    labels = []\n",
        "    for i in range(len(hct)):\n",
        "        #Labels: 0->'O'; 1->'B'; 2->'I'\n",
        "        #labels.append('O')\n",
        "        labels.append(0)\n",
        "\n",
        "    #For Entities (Diseases|Enfermedades)\n",
        "    for enf in et:\n",
        "      first = True\n",
        "      for e in enf:\n",
        "          if first == True:\n",
        "              try:\n",
        "                #labels[hct.index(e)] = 'B'\n",
        "                #labels[posLab] = 'B'\n",
        "                indices = find_idx(hct, e)\n",
        "                if len(indices) > 1:\n",
        "                  for id in indices:\n",
        "                      labels[id] = 1\n",
        "                else:\n",
        "                  labels[hct.index(e)] = 1\n",
        "                \n",
        "                first = False\n",
        "              except:\n",
        "                first = False\n",
        "                if e == \"sarcoma+carcinoma\" or e == \"carcinoma+sarcoma\":\n",
        "                  continue\n",
        "                print(hct)\n",
        "                print(et)\n",
        "                print(enf)\n",
        "                print(e)\n",
        "                print(idx)\n",
        "                sys.exit(0)\n",
        "          else:\n",
        "              try:\n",
        "                #labels[hct.index(e)] = 'I'\n",
        "                #labels[posLab] = 'I'\n",
        "                indices = find_idx(hct, e)\n",
        "                if len(indices) > 1:\n",
        "                  for id in indices:\n",
        "                      if labels[id-1] != 0:\n",
        "                        labels[id] = 2\n",
        "                else:\n",
        "                  labels[hct.index(e)] = 2\n",
        "              except:\n",
        "                if e == \"sarcoma+carcinoma\" or e == \"carcinoma+sarcoma\":\n",
        "                  continue\n",
        "                print(hct)\n",
        "                print(et)\n",
        "                print(enf)\n",
        "                print(e)\n",
        "                print(idx)\n",
        "                sys.exit(0)\n",
        "\n",
        "    labels_tokenized.append(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo_WB3uUWmlK",
        "outputId": "126f438c-f692-4b07-c0ab-8cddc78075a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mujer\t0\n",
            "de\t0\n",
            "74\t0\n",
            "años\t0\n",
            "que\t0\n",
            "ingresó\t0\n",
            "en\t0\n",
            "el\t0\n",
            "hospital\t0\n",
            "por\t0\n",
            "obnubilación\t0\n",
            "y\t0\n",
            "anuria\t0\n",
            "tras\t0\n",
            "presentar\t0\n",
            "durante\t0\n",
            "5\t0\n",
            "días\t0\n",
            "dolor\t0\n",
            "abdominal\t0\n",
            "y\t0\n",
            "vómitos\t0\n",
            ".\t0\n",
            "Entre\t0\n",
            "sus\t0\n",
            "antecedentes\t0\n",
            "destacaba\t0\n",
            "una\t0\n",
            "DM\t1\n",
            "tratada\t0\n",
            "con\t0\n",
            "metformina\t0\n",
            "(\t0\n",
            "850\t0\n",
            "mg/8\t0\n",
            "h\t0\n",
            ")\t0\n",
            "y\t0\n",
            "glibenclamida\t0\n",
            ".\t0\n",
            "La\t0\n",
            "presión\t0\n",
            "arterial\t0\n",
            "era\t0\n",
            "de\t0\n",
            "105/60\t0\n",
            "mmHg\t0\n",
            ",\t0\n",
            "la\t0\n",
            "frecuencia\t0\n",
            "cardíaca\t0\n",
            "de\t0\n",
            "155\t0\n",
            "latidos\t0\n",
            "/\t0\n",
            "minuto\t0\n",
            "y\t0\n",
            "la\t0\n",
            "temperatura\t0\n",
            "de\t0\n",
            "36,7º\t0\n",
            "C.\t0\n",
            "En\t0\n",
            "la\t0\n",
            "exploración\t0\n",
            "destacaba\t0\n",
            "deshidratación\t1\n",
            "intensa\t0\n",
            ",\t0\n",
            "desorientación\t0\n",
            ",\t0\n",
            "respiración\t0\n",
            "de\t0\n",
            "Kussmaul\t0\n",
            ",\t0\n",
            "dolor\t0\n",
            "abdominal\t0\n",
            "con\t0\n",
            "peristaltismo\t0\n",
            "débil\t0\n",
            "y\t0\n",
            "ausencia\t0\n",
            "de\t0\n",
            "defensa\t0\n",
            "abdominal\t0\n",
            ".\t0\n",
            "La\t0\n",
            "tabla\t0\n",
            "2\t0\n",
            "muestra\t0\n",
            "los\t0\n",
            "principales\t0\n",
            "datos\t0\n",
            "analíticos\t0\n",
            ",\t0\n",
            "destacando\t0\n",
            "además\t0\n",
            "una\t0\n",
            "hiperamilasemia\t1\n",
            "de\t2\n",
            "2.605\t0\n",
            "U\t0\n",
            "/\t0\n",
            "l\t0\n",
            ".\t0\n",
            "Una\t0\n",
            "tomografía\t0\n",
            "computarizada\t0\n",
            "abdominal\t0\n",
            "descubrió\t0\n",
            "un\t0\n",
            "aumento\t0\n",
            "del\t0\n",
            "tamaño\t0\n",
            "de\t0\n",
            "la\t0\n",
            "cabeza\t0\n",
            "del\t0\n",
            "páncreas\t0\n",
            "sugerente\t0\n",
            "de\t0\n",
            "pancreatitis\t1\n",
            "aguda\t2\n",
            ".\t0\n",
            "Tras\t0\n",
            "suspender\t0\n",
            "la\t0\n",
            "administración\t0\n",
            "de\t0\n",
            "metformina\t0\n",
            ",\t0\n",
            "la\t0\n",
            "paciente\t0\n",
            "fue\t0\n",
            "intubada\t0\n",
            "orotraquealmente\t0\n",
            "y\t0\n",
            "conectada\t0\n",
            "a\t0\n",
            "un\t0\n",
            "respirador\t0\n",
            "mecánico\t0\n",
            ".\t0\n",
            "También\t0\n",
            "recibió\t0\n",
            "tratamiento\t0\n",
            "a\t0\n",
            "base\t0\n",
            "de\t0\n",
            "fluidos\t0\n",
            "con\t0\n",
            "suplementos\t0\n",
            "de\t0\n",
            "potasio\t0\n",
            ",\t0\n",
            "noradrenalina\t0\n",
            ",\t0\n",
            "bicarbonato\t0\n",
            ",\t0\n",
            "insulina\t0\n",
            ",\t0\n",
            "amiodarona\t0\n",
            ",\t0\n",
            "imipenen\t0\n",
            "y\t0\n",
            "furosemida\t0\n",
            ".\t0\n",
            "Al\t0\n",
            "segundo\t0\n",
            "día\t0\n",
            "de\t0\n",
            "ingreso\t0\n",
            ",\t0\n",
            "tras\t0\n",
            "administrar\t0\n",
            "750\t0\n",
            "mEq\t0\n",
            "de\t0\n",
            "bicarbonato\t0\n",
            "y\t0\n",
            "140\t0\n",
            "mEq\t0\n",
            "de\t0\n",
            "potasio\t0\n",
            ",\t0\n",
            "se\t0\n",
            "normalizó\t0\n",
            "el\t0\n",
            "equilibrio\t0\n",
            "ácido\t0\n",
            "-\t0\n",
            "básico\t0\n",
            "(\t0\n",
            "pH\t0\n",
            "7,41\t0\n",
            "y\t0\n",
            "bicarbonato\t0\n",
            "20\t0\n",
            "mEq\t0\n",
            "/\t0\n",
            "l\t0\n",
            ")\t0\n",
            "e\t0\n",
            "hidroelectrolítico\t0\n",
            "(\t0\n",
            "sodio\t0\n",
            "147\t0\n",
            "mEq\t0\n",
            "/\t0\n",
            "l\t0\n",
            ",\t0\n",
            "potasio\t0\n",
            "3,5\t0\n",
            "mEq\t0\n",
            "/\t0\n",
            "l\t0\n",
            ")\t0\n",
            "y\t0\n",
            "la\t0\n",
            "creatinina\t0\n",
            "descendió\t0\n",
            "a\t0\n",
            "5,5\t0\n",
            "mg\t0\n",
            "/\t0\n",
            "dl\t0\n",
            ".\t0\n",
            "Al\t0\n",
            "tercer\t0\n",
            "día\t0\n",
            "de\t0\n",
            "ingreso\t0\n",
            ",\t0\n",
            "por\t0\n",
            "la\t0\n",
            "presencia\t0\n",
            "de\t0\n",
            "deposiciones\t0\n",
            "mucosas\t0\n",
            "repetidas\t0\n",
            ",\t0\n",
            "se\t0\n",
            "realizó\t0\n",
            "una\t0\n",
            "colonoscopia\t0\n",
            "que\t0\n",
            "puso\t0\n",
            "de\t0\n",
            "manifiesto\t0\n",
            "una\t0\n",
            "formación\t1\n",
            "polipoidea\t2\n",
            "sésil\t2\n",
            "situada\t2\n",
            "junto\t2\n",
            "al\t2\n",
            "esfínter\t2\n",
            "anal\t2\n",
            "y\t0\n",
            "de\t0\n",
            "14\t0\n",
            "cm\t0\n",
            "de\t0\n",
            "longitud\t0\n",
            ".\t0\n",
            "La\t0\n",
            "muestra\t0\n",
            "endoscópica\t0\n",
            "fue\t0\n",
            "informada\t0\n",
            "como\t0\n",
            "adenoma\t1\n",
            "velloso\t2\n",
            "de\t2\n",
            "recto\t2\n",
            ".\t0\n",
            "Al\t0\n",
            "séptimo\t0\n",
            "día\t0\n",
            "de\t0\n",
            "ingreso\t0\n",
            "la\t0\n",
            "enferma\t0\n",
            "fue\t0\n",
            "extubada\t0\n",
            ",\t0\n",
            "y\t0\n",
            "dos\t0\n",
            "días\t0\n",
            "más\t0\n",
            "tarde\t0\n",
            "fue\t0\n",
            "trasladada\t0\n",
            "a\t0\n",
            "planta\t0\n",
            "para\t0\n",
            "extirpación\t0\n",
            "del\t0\n",
            "adenoma\t1\n",
            "\n",
            "\t0\n"
          ]
        }
      ],
      "source": [
        "j = 0\n",
        "for i in range(len(HCs_tokenized[j])):\n",
        "  print(str(HCs_tokenized[j][i]) + \"\\t\" + str(labels_tokenized[j][i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0OdnKiDSCn-"
      },
      "source": [
        "## Validating tokenization and alignment with the BIO tags.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61hktW4PR-bt",
        "outputId": "c126fd7a-e3ab-44b0-bc9e-b5b4c08465df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything is aligned!\n"
          ]
        }
      ],
      "source": [
        "flag = 0\n",
        "for st, lt in zip(HCs_tokenized, labels_tokenized):\n",
        "    if len(st) != len(lt):\n",
        "        print(st)\n",
        "        print(lt)\n",
        "        flag = 1\n",
        "if flag==0:\n",
        "    print(\"Everything is aligned!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence tokenization is an alternative but we finally used the whole clinical cases as samples."
      ],
      "metadata": {
        "id": "fPDzmJE6Wgho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeFfLm3Ubu7x"
      },
      "outputs": [],
      "source": [
        "sent_tokenized = []\n",
        "label_sent_tokenized = []\n",
        "for ht, lht in zip(HCs_tokenized, labels_tokenized):\n",
        "  st = []; lbst = []\n",
        "  for h, l in zip(ht,lht):\n",
        "    if h != \".\":\n",
        "      st.append(h)\n",
        "      lbst.append(l)\n",
        "    else:\n",
        "      st.append(\".\")\n",
        "      lbst.append(0)\n",
        "      sent_tokenized.append(st)\n",
        "      label_sent_tokenized.append(lbst)\n",
        "      st = []; lbst = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT7Ig0bcmOQR",
        "outputId": "8068e574-f4dc-4660-8921-7457a9ed0cd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11795"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "len(sent_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czWqzs_pmch5",
        "outputId": "41a0abd7-3afa-4f07-ff53-16ff0400d398"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mujer',\n",
              " 'de',\n",
              " '74',\n",
              " 'años',\n",
              " 'que',\n",
              " 'ingresó',\n",
              " 'en',\n",
              " 'el',\n",
              " 'hospital',\n",
              " 'por',\n",
              " 'obnubilación',\n",
              " 'y',\n",
              " 'anuria',\n",
              " 'tras',\n",
              " 'presentar',\n",
              " 'durante',\n",
              " '5',\n",
              " 'días',\n",
              " 'dolor',\n",
              " 'abdominal',\n",
              " 'y',\n",
              " 'vómitos',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "sent_tokenized[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOsSFm0wmS2I",
        "outputId": "0634c7ec-4e88-4977-a8aa-2c7c3fbb3c52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11795"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "len(label_sent_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx6NtMpxmg2N",
        "outputId": "41fae828-a29a-4533-ebbe-98e3ebfaa2ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "label_sent_tokenized[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RIR3iRCUc0h"
      },
      "source": [
        "# Disease mentions identification as a Token classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WaBFjAEUc0l"
      },
      "source": [
        "## Install the Transformers and Datasets libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEX7xfLiUc0m",
        "outputId": "5ec12eb2-bba0-494e-a10e-5d62819a9824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: dill<0.3.5 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.12.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.96)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.11.0+cu113)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (4.2.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the followin line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Authentication\n",
        "\n",
        "If you want to save your own model and make it available online we strongly recommend signing up at: https://huggingface.co/"
      ],
      "metadata": {
        "id": "K90ROU-SaLC5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgxCB7y8Uc0n"
      },
      "source": [
        "You will need to setup git, adapt your email and name in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hstit1gRUc0o"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"your_email\"\n",
        "!git config --global user.name \"your_name\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXbs9i1fUc0o"
      },
      "source": [
        "You will also need to be logged in to the Hugging Face Hub. Execute the following and enter your credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387,
          "referenced_widgets": [
            "be10f0b198604969aa84276332067f31",
            "b3d0bab880604cde8d9e247b49f884b1",
            "3da695ee9bc94ba188a58f699f2f3b01",
            "b13ea0e6e06840d8b93349a79a55581f",
            "d61ef4c367a145ce9b725b878d3a9d8f",
            "ca22d0f855de402fa96ff6f65d621d5d",
            "e820970be81f4f4ea96cd885e0de9650",
            "2381aa4ded5d4ef89360071abe08af5c",
            "c49fe48bdb17407685afbd34b7153d60",
            "1e0c1d998e8b44fbae3fc14a988d43e8",
            "bdc3b3f9f6734176b2fbbadd3150e303",
            "ff36684af72c4705b106ba9b67665136",
            "610a7e46b1f144cc93e532518922becc",
            "ffacec949e2040afac3fad216f3c5bc3",
            "60595746ea1d46b49de2c3a6c73c879d",
            "608445951e32406aa3ad9ce9a29c357d",
            "a79468f630e041a1ba67f6d94bba26b3"
          ]
        },
        "id": "G6SkGUEUUc0p",
        "outputId": "dd55be81-9892-47a5-befc-aba3e9b27a46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be10f0b198604969aa84276332067f31"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9FTB991Sl12"
      },
      "source": [
        "## Building the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KVP5DQ7ZLuG"
      },
      "outputs": [],
      "source": [
        "dic = {\"tokens\": HCs_tokenized, \"ner_tags\": labels_tokenized} #For the whole clinical case. We used this option for our paper.\n",
        "#dic = {\"tokens\": sent_tokenized, \"ner_tags\": label_sent_tokenized} #Use this option if you want to check the model performance with sentences tokenized by \". \" but the whole clinical cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZawOY4qqSoz6"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "dataset = Dataset.from_dict(dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTBNV4yzYuzc",
        "outputId": "5ef425e1-da1b-4dd3-e604-8c0ec1ef3548"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['tokens', 'ner_tags'],\n",
              "    num_rows: 750\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMZbF0mSaOiS"
      },
      "outputs": [],
      "source": [
        "#For training, validation, and test partitions\n",
        "\"\"\"\n",
        "#Train, val, test partitions\n",
        "train_test = dataset.train_test_split()\n",
        "test_val = train_test['test'].train_test_split()\n",
        "raw_datasets = DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'validation': test_val['train'],\n",
        "    'test': test_val['test']\n",
        "    })\n",
        "\"\"\"\n",
        "\n",
        "#Just for training and validation partitions\n",
        "train_test = dataset.train_test_split()\n",
        "raw_datasets = DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'validation': train_test['test']\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFQfd5u9Uc0q",
        "outputId": "dd37d781-d3eb-4e8c-d277-78ddd556ebe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 562\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 188\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI0wWv0aUc0t",
        "outputId": "74d6f75f-79c1-48af-ed91-c48c177e3211"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "#raw_datasets[\"train\"][0][\"pos_tags\"]\n",
        "#raw_datasets[\"train\"][0][\"chunk_tags\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-usgjZalK7E9",
        "outputId": "60527054-3c03-4547-c250-456f11dd125a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['tokens', 'ner_tags'],\n",
              "    num_rows: 562\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "raw_datasets['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLHqEaOVUc0u",
        "outputId": "9ce44d7a-303a-4dbf-a580-b733b1821fea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B', 'I']"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "label_names = ['O','B','I']\n",
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iCYOiwZUc0u",
        "outputId": "c69cbf71-c14e-4f4f-c3ec-57c896fd1233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mujer de 43 años de edad , ama de casa , alérgica al contraste yodado y fumadora de 1 paquete diario de cigarrillos , histerectomizada y ooferectomizada derecha por endometriosis . \n",
            " La paciente se encuentra en estudio por el Servicio de Hematología por leucocitosis aislada ; se le realizó ecografía abdominal hallando un riñón izquierdo desestructurado con imágenes quísticas o hidronefrosis y siendo remitida a nuestras consultas . \n",
            " En el interrogatorio refiere un ingreso de 27 días de duración , cuando tenía 12 años , en otro hospital por dolor lumbar con hematuria sin conocer su diagnóstico . También refiere ocasionales dolores lumbares de tipo mecánico con astenia moderada . \n",
            " Exploración física : sin hallazgos \n",
            " Pruebas complementarias : hemograma con ligera leucocitosis sin desviación de fórmula leucocitaria siendo el resto normal , bioquímica y coagulación normales . \n",
            " Renograma MAG-3-Tc-99 m : riñón derecho normal . Captación heterogénea en riñón izquierdo con dilatación calicilar superior , retención en polo superior izquierdo presentando un enlentecimiento excretor de la curva cuya actividad desaparece en imágenes tardías . \n",
            " TC sin contraste : masa quística renal polar superior izquierda de aproximadamente 12 cm . de diámetro máximo desplazando páncreas y bazo . Internamente constituida por múltiples quistes de diferentes tamaños y presenta tabiques internos heterogéneos , alguno de ellos grueso e irregular sugestivo de nefroma quístico multinodular o carcinoma de células renales quístico . \n",
            " Se decide realizar nefrectomía con linfadenectomía izquierda . En el estudio anatomopatológico de la pieza se informa como riñón que presenta tumoración de 9x10 cm . multiquística que ocupa la mayor parte del riñón . El contenido del quiste es ambarino sin presencia de partes sólidas ni adherencia del tumor en la cápsula . Las cavidades están revestidas de un epitelio simple con presencia de frecuentes células con morfología en \" tachuela \" . El estroma intercelular es fibroso . Lesión bien delimitada del parénquima renal conservado . Diagnóstico anatomopatológico de tumor quístico multilocular benigno de riñón . \n",
            "\n",
            " \n",
            "O     O  O  O    O  O    O O   O  O    O B        I  I         I      O B        O  O O       O      O  O           O O                O O               O       O   B             O O O  O        O  O         O  O       O   O  O        O  O           O   O            O       O O  O  O       O         O         O        O  B     I         I               I   I        I         O B             O O      O        O O        O         O O O  O  O              O       O  O       O  O  O    O  O        O O      O     O  O    O O  O    O        O   O     O      O   O         O   O       O  O           O O       O       O           O       O        O  O    O        O   O       O        O O O           O      O O   O         O O       O               O O         O   O      O            O   O          O  O       O            O      O  O     O      O O          O O           O        O O O         O           O O B     O       O      O O         O           O  B     I         I   I          I         I        O O         O  O    O        O         O           O  O               O        O  O  O     O    O         O          O  O        O       O O O  O   O         O B    I        I     I     I        I         I  O               O  O  O O  O        O      O           O        O O    O O            O           O   B         I       I  O          O       O O        O        O        O            O O      O  O     O      O O         O         O  B       I        I            O B         I  I       I       I        O O O  O      O        O           O   O               O         O O  O  O       O                 O  O  O     O  O       O    B     I   O        B          I  I    I  I I             I   I     I  I     I     I   I     I O  O         O   B      O  O        O   O         O  O      O       O  O          O   B     O  O  O       O O   O         O     O          O  O  O        O      O   O         O  O          O       O   O          O  O O        O O O  O       O            O  O       O B      O    O          O   O          O     O          O O           O                 O  B     I        I            I       I  I     I O  \n"
          ]
        }
      ],
      "source": [
        "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
        "labels = [int(n) for n in raw_datasets[\"train\"][0][\"ner_tags\"]]\n",
        "#labels = raw_datasets[\"train\"][0][\"pos_tags\"]\n",
        "#labels = raw_datasets[\"train\"][0][\"chunk_tags\"]\n",
        "line1 = \"\"\n",
        "line2 = \"\"\n",
        "for word, label in zip(words, labels):\n",
        "    full_label = label_names[label]\n",
        "    max_length = max(len(word), len(full_label))\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "print(line1)\n",
        "print(line2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading mBERT as a pre-trained model"
      ],
      "metadata": {
        "id": "CRKUqAVVbvf7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuZTRxLPUc0v",
        "outputId": "a32ae574-e576-4105-83d4-0405c5fcbf87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
            "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
            "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-multilingual-cased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr7qjUe7Uc0v",
        "outputId": "97b5cf8d-3784-4723-d96f-a849a0760acb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbchCgPGUc0v",
        "outputId": "68c170f5-eb15-4e24-e8d4-7e2914609625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Mujer',\n",
              " 'de',\n",
              " '43',\n",
              " 'años',\n",
              " 'de',\n",
              " 'edad',\n",
              " ',',\n",
              " 'ama',\n",
              " 'de',\n",
              " 'casa',\n",
              " ',',\n",
              " 'al',\n",
              " '##ér',\n",
              " '##gica',\n",
              " 'al',\n",
              " 'contraste',\n",
              " 'yo',\n",
              " '##dado',\n",
              " 'y',\n",
              " 'fu',\n",
              " '##mad',\n",
              " '##ora',\n",
              " 'de',\n",
              " '1',\n",
              " 'pa',\n",
              " '##quet',\n",
              " '##e',\n",
              " 'diario',\n",
              " 'de',\n",
              " 'ci',\n",
              " '##garri',\n",
              " '##llos',\n",
              " ',',\n",
              " 'his',\n",
              " '##tere',\n",
              " '##cto',\n",
              " '##mi',\n",
              " '##zada',\n",
              " 'y',\n",
              " 'o',\n",
              " '##of',\n",
              " '##ere',\n",
              " '##cto',\n",
              " '##mi',\n",
              " '##zada',\n",
              " 'derecha',\n",
              " 'por',\n",
              " 'end',\n",
              " '##ome',\n",
              " '##tri',\n",
              " '##osis',\n",
              " '.',\n",
              " 'La',\n",
              " 'paciente',\n",
              " 'se',\n",
              " 'encuentra',\n",
              " 'en',\n",
              " 'estudio',\n",
              " 'por',\n",
              " 'el',\n",
              " 'Servicio',\n",
              " 'de',\n",
              " 'He',\n",
              " '##mat',\n",
              " '##ología',\n",
              " 'por',\n",
              " 'le',\n",
              " '##uco',\n",
              " '##cito',\n",
              " '##sis',\n",
              " 'ai',\n",
              " '##sla',\n",
              " '##da',\n",
              " ';',\n",
              " 'se',\n",
              " 'le',\n",
              " 'realizó',\n",
              " 'e',\n",
              " '##co',\n",
              " '##grafía',\n",
              " 'ab',\n",
              " '##dom',\n",
              " '##inal',\n",
              " 'hall',\n",
              " '##ando',\n",
              " 'un',\n",
              " 'ri',\n",
              " '##ñón',\n",
              " 'izquierdo',\n",
              " 'des',\n",
              " '##est',\n",
              " '##ru',\n",
              " '##ctura',\n",
              " '##do',\n",
              " 'con',\n",
              " 'imágenes',\n",
              " 'qu',\n",
              " '##ísticas',\n",
              " 'o',\n",
              " 'hi',\n",
              " '##dron',\n",
              " '##ef',\n",
              " '##ros',\n",
              " '##is',\n",
              " 'y',\n",
              " 'siendo',\n",
              " 're',\n",
              " '##mitida',\n",
              " 'a',\n",
              " 'nuestra',\n",
              " '##s',\n",
              " 'consulta',\n",
              " '##s',\n",
              " '.',\n",
              " 'En',\n",
              " 'el',\n",
              " 'inter',\n",
              " '##roga',\n",
              " '##torio',\n",
              " 'refiere',\n",
              " 'un',\n",
              " 'ingreso',\n",
              " 'de',\n",
              " '27',\n",
              " 'días',\n",
              " 'de',\n",
              " 'duración',\n",
              " ',',\n",
              " 'cuando',\n",
              " 'tenía',\n",
              " '12',\n",
              " 'años',\n",
              " ',',\n",
              " 'en',\n",
              " 'otro',\n",
              " 'hospital',\n",
              " 'por',\n",
              " 'dolor',\n",
              " 'lu',\n",
              " '##mbar',\n",
              " 'con',\n",
              " 'hem',\n",
              " '##atur',\n",
              " '##ia',\n",
              " 'sin',\n",
              " 'conocer',\n",
              " 'su',\n",
              " 'dia',\n",
              " '##gnóstico',\n",
              " '.',\n",
              " 'También',\n",
              " 'refiere',\n",
              " 'oca',\n",
              " '##sional',\n",
              " '##es',\n",
              " 'dolor',\n",
              " '##es',\n",
              " 'lu',\n",
              " '##mbar',\n",
              " '##es',\n",
              " 'de',\n",
              " 'tipo',\n",
              " 'me',\n",
              " '##cán',\n",
              " '##ico',\n",
              " 'con',\n",
              " 'as',\n",
              " '##tenia',\n",
              " 'mode',\n",
              " '##rada',\n",
              " '.',\n",
              " 'Ex',\n",
              " '##plo',\n",
              " '##ración',\n",
              " 'física',\n",
              " ':',\n",
              " 'sin',\n",
              " 'hall',\n",
              " '##azgo',\n",
              " '##s',\n",
              " 'Pr',\n",
              " '##ue',\n",
              " '##bas',\n",
              " 'complement',\n",
              " '##arias',\n",
              " ':',\n",
              " 'hem',\n",
              " '##og',\n",
              " '##rama',\n",
              " 'con',\n",
              " 'lige',\n",
              " '##ra',\n",
              " 'le',\n",
              " '##uco',\n",
              " '##cito',\n",
              " '##sis',\n",
              " 'sin',\n",
              " 'des',\n",
              " '##via',\n",
              " '##ción',\n",
              " 'de',\n",
              " 'fórmula',\n",
              " 'le',\n",
              " '##uco',\n",
              " '##citar',\n",
              " '##ia',\n",
              " 'siendo',\n",
              " 'el',\n",
              " 'resto',\n",
              " 'normal',\n",
              " ',',\n",
              " 'bio',\n",
              " '##quí',\n",
              " '##mica',\n",
              " 'y',\n",
              " 'coa',\n",
              " '##gula',\n",
              " '##ción',\n",
              " 'normale',\n",
              " '##s',\n",
              " '.',\n",
              " 'Reno',\n",
              " '##grama',\n",
              " 'MA',\n",
              " '##G',\n",
              " '-',\n",
              " '3',\n",
              " '-',\n",
              " 'T',\n",
              " '##c',\n",
              " '-',\n",
              " '99',\n",
              " 'm',\n",
              " ':',\n",
              " 'ri',\n",
              " '##ñón',\n",
              " 'derecho',\n",
              " 'normal',\n",
              " '.',\n",
              " 'Cap',\n",
              " '##tación',\n",
              " 'heter',\n",
              " '##og',\n",
              " '##én',\n",
              " '##ea',\n",
              " 'en',\n",
              " 'ri',\n",
              " '##ñón',\n",
              " 'izquierdo',\n",
              " 'con',\n",
              " 'dil',\n",
              " '##ata',\n",
              " '##ción',\n",
              " 'cal',\n",
              " '##ici',\n",
              " '##lar',\n",
              " 'superior',\n",
              " ',',\n",
              " 'rete',\n",
              " '##nció',\n",
              " '##n',\n",
              " 'en',\n",
              " 'polo',\n",
              " 'superior',\n",
              " 'izquierdo',\n",
              " 'presentan',\n",
              " '##do',\n",
              " 'un',\n",
              " 'en',\n",
              " '##lent',\n",
              " '##eci',\n",
              " '##miento',\n",
              " 'ex',\n",
              " '##cret',\n",
              " '##or',\n",
              " 'de',\n",
              " 'la',\n",
              " 'curva',\n",
              " 'cuya',\n",
              " 'actividad',\n",
              " 'desa',\n",
              " '##parece',\n",
              " 'en',\n",
              " 'imágenes',\n",
              " 'tard',\n",
              " '##ías',\n",
              " '.',\n",
              " 'TC',\n",
              " 'sin',\n",
              " 'contraste',\n",
              " ':',\n",
              " 'masa',\n",
              " 'qu',\n",
              " '##ística',\n",
              " 'ren',\n",
              " '##al',\n",
              " 'polar',\n",
              " 'superior',\n",
              " 'izquierda',\n",
              " 'de',\n",
              " 'aproximadamente',\n",
              " '12',\n",
              " 'cm',\n",
              " '.',\n",
              " 'de',\n",
              " 'diámetro',\n",
              " 'máximo',\n",
              " 'des',\n",
              " '##pla',\n",
              " '##zando',\n",
              " 'p',\n",
              " '##án',\n",
              " '##cre',\n",
              " '##as',\n",
              " 'y',\n",
              " 'ba',\n",
              " '##zo',\n",
              " '.',\n",
              " 'Inter',\n",
              " '##nament',\n",
              " '##e',\n",
              " 'con',\n",
              " '##sti',\n",
              " '##tui',\n",
              " '##da',\n",
              " 'por',\n",
              " 'múltiples',\n",
              " 'qui',\n",
              " '##stes',\n",
              " 'de',\n",
              " 'diferentes',\n",
              " 'tamaño',\n",
              " '##s',\n",
              " 'y',\n",
              " 'presenta',\n",
              " 'tab',\n",
              " '##iques',\n",
              " 'internos',\n",
              " 'heter',\n",
              " '##og',\n",
              " '##én',\n",
              " '##eos',\n",
              " ',',\n",
              " 'algun',\n",
              " '##o',\n",
              " 'de',\n",
              " 'ellos',\n",
              " 'gr',\n",
              " '##ues',\n",
              " '##o',\n",
              " 'e',\n",
              " 'irregular',\n",
              " 'su',\n",
              " '##gest',\n",
              " '##ivo',\n",
              " 'de',\n",
              " 'nef',\n",
              " '##roma',\n",
              " 'qu',\n",
              " '##ístico',\n",
              " 'multi',\n",
              " '##nod',\n",
              " '##ular',\n",
              " 'o',\n",
              " 'car',\n",
              " '##cino',\n",
              " '##ma',\n",
              " 'de',\n",
              " 'células',\n",
              " 'ren',\n",
              " '##ales',\n",
              " 'qu',\n",
              " '##ístico',\n",
              " '.',\n",
              " 'Se',\n",
              " 'decide',\n",
              " 'realizar',\n",
              " 'nef',\n",
              " '##rec',\n",
              " '##tom',\n",
              " '##ía',\n",
              " 'con',\n",
              " 'li',\n",
              " '##n',\n",
              " '##fa',\n",
              " '##dene',\n",
              " '##cto',\n",
              " '##mí',\n",
              " '##a',\n",
              " 'izquierda',\n",
              " '.',\n",
              " 'En',\n",
              " 'el',\n",
              " 'estudio',\n",
              " 'ana',\n",
              " '##tom',\n",
              " '##opa',\n",
              " '##tol',\n",
              " '##ógico',\n",
              " 'de',\n",
              " 'la',\n",
              " 'pieza',\n",
              " 'se',\n",
              " 'informa',\n",
              " 'como',\n",
              " 'ri',\n",
              " '##ñón',\n",
              " 'que',\n",
              " 'presenta',\n",
              " 'tumor',\n",
              " '##ación',\n",
              " 'de',\n",
              " '9',\n",
              " '##x',\n",
              " '##10',\n",
              " 'cm',\n",
              " '.',\n",
              " 'multi',\n",
              " '##quí',\n",
              " '##stica',\n",
              " 'que',\n",
              " 'ocupa',\n",
              " 'la',\n",
              " 'mayor',\n",
              " 'parte',\n",
              " 'del',\n",
              " 'ri',\n",
              " '##ñón',\n",
              " '.',\n",
              " 'El',\n",
              " 'contenido',\n",
              " 'del',\n",
              " 'qui',\n",
              " '##ste',\n",
              " 'es',\n",
              " 'amb',\n",
              " '##arin',\n",
              " '##o',\n",
              " 'sin',\n",
              " 'presencia',\n",
              " 'de',\n",
              " 'partes',\n",
              " 'só',\n",
              " '##lida',\n",
              " '##s',\n",
              " 'ni',\n",
              " 'ad',\n",
              " '##here',\n",
              " '##ncia',\n",
              " 'del',\n",
              " 'tumor',\n",
              " 'en',\n",
              " 'la',\n",
              " 'cá',\n",
              " '##ps',\n",
              " '##ula',\n",
              " '.',\n",
              " 'Las',\n",
              " 'ca',\n",
              " '##vidade',\n",
              " '##s',\n",
              " 'están',\n",
              " 'rev',\n",
              " '##esti',\n",
              " '##das',\n",
              " 'de',\n",
              " 'un',\n",
              " 'epi',\n",
              " '##teli',\n",
              " '##o',\n",
              " 'simple',\n",
              " 'con',\n",
              " 'presencia',\n",
              " 'de',\n",
              " 'frecuentes',\n",
              " 'células',\n",
              " 'con',\n",
              " 'mor',\n",
              " '##fo',\n",
              " '##logía',\n",
              " 'en',\n",
              " '\"',\n",
              " 'ta',\n",
              " '##chu',\n",
              " '##ela',\n",
              " '\"',\n",
              " '.',\n",
              " 'El',\n",
              " 'est',\n",
              " '##roma',\n",
              " 'inter',\n",
              " '##cel',\n",
              " '##ular',\n",
              " 'es',\n",
              " 'fi',\n",
              " '##bros',\n",
              " '##o',\n",
              " '.',\n",
              " 'Les',\n",
              " '##ión',\n",
              " 'bien',\n",
              " 'del',\n",
              " '##imit',\n",
              " '##ada',\n",
              " 'del',\n",
              " 'par',\n",
              " '##én',\n",
              " '##qui',\n",
              " '##ma',\n",
              " 'ren',\n",
              " '##al',\n",
              " 'conserva',\n",
              " '##do',\n",
              " '.',\n",
              " 'Dia',\n",
              " '##gnóstico',\n",
              " 'ana',\n",
              " '##tom',\n",
              " '##opa',\n",
              " '##tol',\n",
              " '##ógico',\n",
              " 'de',\n",
              " 'tumor',\n",
              " 'qu',\n",
              " '##ístico',\n",
              " 'multi',\n",
              " '##loc',\n",
              " '##ular',\n",
              " 'beni',\n",
              " '##gno',\n",
              " 'de',\n",
              " 'ri',\n",
              " '##ñón',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
        "inputs.tokens()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udiVaGenUc0w",
        "outputId": "0a5783f2-3587-433b-d651-040dbae49e4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 11,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 19,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 22,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 24,\n",
              " 24,\n",
              " 24,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 26,\n",
              " 26,\n",
              " 26,\n",
              " 26,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 29,\n",
              " 29,\n",
              " 29,\n",
              " 30,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 42,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 44,\n",
              " 44,\n",
              " 44,\n",
              " 45,\n",
              " 45,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 50,\n",
              " 50,\n",
              " 51,\n",
              " 51,\n",
              " 51,\n",
              " 52,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 56,\n",
              " 56,\n",
              " 56,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 61,\n",
              " 61,\n",
              " 61,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 66,\n",
              " 67,\n",
              " 67,\n",
              " 68,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 72,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 94,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 102,\n",
              " 102,\n",
              " 103,\n",
              " 103,\n",
              " 104,\n",
              " 104,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 107,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 109,\n",
              " 110,\n",
              " 110,\n",
              " 111,\n",
              " 113,\n",
              " 113,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 117,\n",
              " 117,\n",
              " 119,\n",
              " 119,\n",
              " 119,\n",
              " 120,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 122,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 124,\n",
              " 125,\n",
              " 125,\n",
              " 125,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 127,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 130,\n",
              " 130,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 136,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 138,\n",
              " 138,\n",
              " 139,\n",
              " 139,\n",
              " 140,\n",
              " 142,\n",
              " 142,\n",
              " 143,\n",
              " 143,\n",
              " 143,\n",
              " 143,\n",
              " 143,\n",
              " 143,\n",
              " 143,\n",
              " 143,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 150,\n",
              " 151,\n",
              " 151,\n",
              " 151,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 156,\n",
              " 156,\n",
              " 157,\n",
              " 157,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 160,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 167,\n",
              " 167,\n",
              " 167,\n",
              " 168,\n",
              " 168,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 177,\n",
              " 178,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 185,\n",
              " 186,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 198,\n",
              " 198,\n",
              " 199,\n",
              " 199,\n",
              " 199,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 203,\n",
              " 203,\n",
              " 204,\n",
              " 204,\n",
              " 204,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 215,\n",
              " 215,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 220,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 223,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 225,\n",
              " 226,\n",
              " 226,\n",
              " 227,\n",
              " 227,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 229,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 232,\n",
              " 233,\n",
              " 233,\n",
              " 234,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 239,\n",
              " 239,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 241,\n",
              " 241,\n",
              " 241,\n",
              " 241,\n",
              " 241,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 247,\n",
              " 247,\n",
              " 247,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 259,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 262,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 276,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 281,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 283,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 288,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 291,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 293,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 296,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 304,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 307,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 311,\n",
              " 312,\n",
              " 312,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 314,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 318,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 320,\n",
              " 320,\n",
              " 320,\n",
              " 321,\n",
              " 321,\n",
              " 322,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 324,\n",
              " 325,\n",
              " 325,\n",
              " 325,\n",
              " 325,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 328,\n",
              " 329,\n",
              " 329,\n",
              " 329,\n",
              " 330,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 332,\n",
              " 333,\n",
              " None]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "inputs.word_ids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhu4Cl3-Uc0w"
      },
      "outputs": [],
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            # If the label is B-XXX we change it to I-XXX\n",
        "            if label % 2 == 1:\n",
        "                label += 1\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H820wg0sUc0x",
        "outputId": "3aa43974-527d-464f-fef7-5bf7c4c728e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0]\n",
            "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, -100]\n"
          ]
        }
      ],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-ZxnhGSUc0x"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f68660f7cf1a4f14b46807d4026aa137",
            "0090194cbfe84036b23ba9d38bcf9161",
            "9d1a091689054f71aa807f1408b86aa9",
            "fbd8aeede62e47dbbf0559db51ce6b41",
            "50a34c17a1e74e3aae1f49037e866a6c",
            "4b51d0d7a0384e53950f44fb38fcb5ee",
            "defda63cc410427e8e6e69e9e1300a56",
            "4b4065e943884cdb8b47f31ecf7e2bc3",
            "d5c5d08df78c458bae2c1d1af42272c9",
            "feef01dd690049db8f4728a84ca14b49",
            "12ef2e02cc9b4407b22b0ba7ec285829",
            "415065514b8c44f28c8b9b6d7e67fdfd",
            "9902a89f99644d5daf8e99e44b283e5e",
            "cfb2e475c10e45d4b851e895bc9b49bb",
            "a39a848a5cc04157bddd97031807a3ed",
            "1292e58708264469a50505ea9e36bd56",
            "2a8e0c4d04534d2b81ad2b93a0c82c29",
            "9345205e5e40454a9816a04ad4756f8f",
            "6828783293ce4f0890f3d0056ffcd207",
            "4b5dc760f653414083a00e24fe9a737b",
            "f38bbf811b2848b1bcf50a99a8de912c",
            "2779dee281b14a0f9d07e5f794ff9e1a"
          ]
        },
        "id": "INNjCms4Uc0y",
        "outputId": "483d8ba2-691e-4759-a409-24c1935aaf17"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f68660f7cf1a4f14b46807d4026aa137"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "415065514b8c44f28c8b9b6d7e67fdfd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFpUXjvmUc0y"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHCuXD5EUc0y",
        "outputId": "3192ebef-2ca8-4160-c6e7-59a2de19185f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    0,    0,  ...,    0,    0, -100],\n",
              "        [-100,    0,    0,  ...,    0,    0, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6GW37IPUc0z",
        "outputId": "5e9cfc10-ac66-4065-aac7-c3436273a4f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n",
            "[-100, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
          ]
        }
      ],
      "source": [
        "for i in range(2):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImHtQb6HUc0z",
        "outputId": "74640b98-365d-4134-a4ef-f5964b2792fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDjn2La4Uc0z"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mqjInn4Uc0z",
        "outputId": "e4d16008-d56c-4ece-c9af-02d271dcbac6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'O',\n",
              " 'B',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'O',\n",
              " 'B',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'I',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'I',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "labels = [label_names[i] for i in labels]\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIaLt4n-Uc00",
        "outputId": "87e2ba4a-4220-4081-8b85-40e5783aadba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_': {'f1': 1.0, 'number': 17, 'precision': 1.0, 'recall': 1.0},\n",
              " 'overall_accuracy': 1.0,\n",
              " 'overall_f1': 1.0,\n",
              " 'overall_precision': 1.0,\n",
              " 'overall_recall': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "predictions = labels.copy()\n",
        "predictions[2] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xewJhf6Uc00"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdmwR_2HUc00"
      },
      "outputs": [],
      "source": [
        "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svP0J1bWs3pK",
        "outputId": "78cc229b-ba8d-447a-eac5-954301f3cf27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'O', '1': 'B', '2': 'I'}"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvIvq5wxs8P8",
        "outputId": "c3281b64-e9b8-4369-947d-5b222e5d946f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B': '1', 'I': '2', 'O': '0'}"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "label2id"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing the head of prediction for Disease Mentions Identification under the BIO scheme"
      ],
      "metadata": {
        "id": "FKNvor68cVQs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Rrve75Uc00",
        "outputId": "3b8e4fd7-35f6-4ac1-c892-1a2bcba00981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"B\",\n",
            "    \"2\": \"I\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B\": \"1\",\n",
            "    \"I\": \"2\",\n",
            "    \"O\": \"0\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(    \n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    num_labels = 3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDiAYqsYUc00",
        "outputId": "7ab9adb7-2d44-4af0-c334-d2f28560deee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "model.config.num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS-L0U1XUc01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5199068-97fe-4aa9-d37f-2bdccf8a0ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"NLP-CIC-WFU_DisTEMIST_fine_tuned_bert-base-multilingual-cased\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning mBERT for Disease mentions identification"
      ],
      "metadata": {
        "id": "tdHv4CMvctoB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RvHls_JJUc01",
        "outputId": "2cda3bf6-54dc-4cc9-8e6c-ec6e33763c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 562\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 497\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='497' max='497' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [497/497 08:56, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.168280</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>0.461812</td>\n",
              "      <td>0.394837</td>\n",
              "      <td>0.933139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.150811</td>\n",
              "      <td>0.480986</td>\n",
              "      <td>0.531676</td>\n",
              "      <td>0.505062</td>\n",
              "      <td>0.947419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.149166</td>\n",
              "      <td>0.513579</td>\n",
              "      <td>0.503848</td>\n",
              "      <td>0.508667</td>\n",
              "      <td>0.948371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.158576</td>\n",
              "      <td>0.515303</td>\n",
              "      <td>0.548253</td>\n",
              "      <td>0.531268</td>\n",
              "      <td>0.950063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.182369</td>\n",
              "      <td>0.532330</td>\n",
              "      <td>0.565423</td>\n",
              "      <td>0.548378</td>\n",
              "      <td>0.950694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.189381</td>\n",
              "      <td>0.521022</td>\n",
              "      <td>0.579633</td>\n",
              "      <td>0.548767</td>\n",
              "      <td>0.951385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.204927</td>\n",
              "      <td>0.522951</td>\n",
              "      <td>0.566607</td>\n",
              "      <td>0.543905</td>\n",
              "      <td>0.952016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 188\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-71\n",
            "Configuration saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-71/config.json\n",
            "Model weights saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-71/pytorch_model.bin\n",
            "tokenizer config file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-71/tokenizer_config.json\n",
            "Special tokens file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-71/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 188\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-142\n",
            "Configuration saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-142/config.json\n",
            "Model weights saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-142/pytorch_model.bin\n",
            "tokenizer config file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-142/tokenizer_config.json\n",
            "Special tokens file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-142/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 188\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-213\n",
            "Configuration saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-213/config.json\n",
            "Model weights saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-213/pytorch_model.bin\n",
            "tokenizer config file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-213/tokenizer_config.json\n",
            "Special tokens file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-213/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 188\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-284\n",
            "Configuration saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-284/config.json\n",
            "Model weights saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-284/pytorch_model.bin\n",
            "tokenizer config file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-284/tokenizer_config.json\n",
            "Special tokens file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-284/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 188\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-355\n",
            "Configuration saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-355/config.json\n",
            "Model weights saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-355/pytorch_model.bin\n",
            "tokenizer config file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-355/tokenizer_config.json\n",
            "Special tokens file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-355/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 188\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-426\n",
            "Configuration saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-426/config.json\n",
            "Model weights saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-426/pytorch_model.bin\n",
            "tokenizer config file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-426/tokenizer_config.json\n",
            "Special tokens file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-426/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 188\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-497\n",
            "Configuration saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-497/config.json\n",
            "Model weights saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-497/pytorch_model.bin\n",
            "tokenizer config file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-497/tokenizer_config.json\n",
            "Special tokens file saved in NER_EHR_Spanish_model_bert-base-multilingual-cased/checkpoint-497/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=497, training_loss=0.08985690571652571, metrics={'train_runtime': 537.2858, 'train_samples_per_second': 7.322, 'train_steps_per_second': 0.925, 'total_flos': 1027794567503484.0, 'train_loss': 0.08985690571652571, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the fine-tuned model at Hugging Face (It requires previous authentication)"
      ],
      "metadata": {
        "id": "0rGdJ42qc3sh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAvTQZClUc01"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(commit_message=\"Training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "485I5jdmd6Dr"
      },
      "source": [
        "## Analyzing predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk5cSus7d5cA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1puArlhRe7_o"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "print(raw_datasets[\"validation\"][i]['tokens'])\n",
        "for j in range(len(preds[i])):\n",
        "  print(raw_datasets[\"validation\"][i]['ner_tags'][j], \"\\t\", preds[i][j])\n",
        "print(' '.join(raw_datasets[\"validation\"][i]['tokens']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjEM4d77Toxs"
      },
      "source": [
        "## Loading the model for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKO5fyKyUc04"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "#Replace this with your own checkpoint. If you have run all the previous cells successfully, the model should be available at your hugging face account with the name: NLP-CIC-WFU_DisTEMIST_fine_tuned_bert-base-multilingual-cased\n",
        "model_checkpoint = \"ajtamayoh/NER_EHR_Spanish_model_Mulitlingual_BERT\"\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr7QlXqoaaMZ"
      },
      "outputs": [],
      "source": [
        "#pred = token_classifier(\"Mujer de 74 años que ingresó en el hospital por obnubilación y anuria tras presentar durante 5 días dolor abdominal y vómitos.\")\n",
        "pred = token_classifier(\"Entre sus antecedentes destacaba una DM tratada con metformina (850 mg/8 h) y glibenclamida.\")\n",
        "#pred = token_classifier(\"Anamnesis\\nPresentamos el caso de un varón de 69 años de edad con antecedentes de ángor estable desde hace más de un año, remitido desde Atención Primaria por síntomas de tracto urinario inferior. El paciente presenta una puntuación de síntomas prostáticos (IPSS) de 9; refiere erección satisfactoria, con test de la disfunción eréctil (IIEF-5) de 23.\\n\\nExploración física\\nComplexión corporal normal, con un índice de masa corporal de 20. Al tacto rectal se palpa una próstata sin hallazgos patológicos de interés.\\n\\nPruebas complementarias\\n• A nivel analítico se evidencia un antígeno prostático específico (PSA) de 7,22 con cociente PSA libre/PSA total de 0,19.\\n• En la ecografía transrectal se aprecia una próstata de 44 g.\\n• Se realiza una biopsia transrectal ecodirigida de próstata, con resultado de adenocarcinoma de próstata Gleason 6 (3 + 3) en el lóbulo derecho.\\n\\nTratamiento y evolución\\nTras ofrecer las distintas opciones de tratamiento, el paciente opta por prostatectomía radical robótica. Se realiza un abordaje intraperitoneal con movilización vesical para acceder al espacio de Retzius. Tras la liberación de la grasa periprostática y la apertura de la fascia endopélvica se advierte la presencia de arterias pudendas accesorias (APA) bilaterales. Ambas APA transcurren en íntima relación con la cápsula prostática, siendo necesaria una disección minuciosa para su conservación.\\nTras identificar el cuello vesical, se procede a su sección para acceder al espacio retroprostático. Se disecan y liberan los conductos deferentes y vesículas seminales. A continuación se procede a una disección interfascial bilateral de bandeletas neurovasculares para su preservación. Tras la sección de los ligamentos puboprostáticos y del plexo de Santorini se secciona la uretra. Una vez preservadas ambas APA se procede a la anastomosis vesicouretral con sutura de monofilamento reabsorbible según la técnica de Van Velthoven. Por último, se procede al llenado de la vejiga para comprobar la estanqueidad de la sutura. Sangrado aproximado intraoperatorio de 300 ml, tiempo de consola 120 minutos.\\nEn las revisiones ulteriores el paciente recupera de forma progresiva la función eréctil, consiguiendo en la última revisión al año un IIEF de 17. El valor del PSA en la última revisión se mantiene en 0,00.\\n\")\n",
        "#pred = token_classifier(\"El segundo caso que se presenta es el de una lactante de 2 meses que acudió a urgencias por febrícula y un cuadro de urticaria aguda, aparentemente pruriginoso, de 4 días de evolución. Inicialmente afectaba la cara y las extremidades superiores, extendiéndose en pocas horas al tronco y las extremidades inferiores. Exantema urticariforme. No había afectación palmoplantar. Estas manifestaciones no se acompañaban de angioedema acral, labial ni lingual.\\n\\nComo antecedente epidemiológico destacable, la paciente convivía con 2 personas con COVID-19 demostrada, por lo que se realizó PCR a SARS-CoV-2 en aspirado nasofaríngeo, que fue positiva. Se pautó tratamiento sintomático vía oral con buena respuesta. La duración de la mayoría de las lesiones fue inferior a 24h, resolviéndose la clínica cutánea en 5 días, sin otras manifestaciones asociadas.\")\n",
        "#pred = token_classifier(\"Mujer de 74 años que ingresó en el hospital por obnubilación y anuria tras presentar durante 5 días dolor abdominal y vómitos. Entre sus antecedentes destacaba una DM tratada con metformina (850 mg/8 h) y glibenclamida. La presión arterial era de 105/60 mmHg, la frecuencia cardíaca de 155 latidos/minuto y la temperatura de 36,7º C. En la exploración destacaba deshidratación intensa, desorientación, respiración de Kussmaul, dolor abdominal con peristaltismo débil y ausencia de defensa abdominal. La tabla 2 muestra los principales datos analíticos, destacando además una hiperamilasemia de 2.605 U/l. Una tomografía computarizada abdominal descubrió un aumento del tamaño de la cabeza del páncreas sugerente de pancreatitis aguda. Tras suspender la administración de metformina, la paciente fue intubada orotraquealmente y conectada a un respirador mecánico. También recibió tratamiento a base de fluidos con suplementos de potasio, noradrenalina, bicarbonato, insulina, amiodarona, imipenen y furosemida. Al segundo día de ingreso, tras administrar 750 mEq de bicarbonato y 140 mEq de potasio, se normalizó el equilibrio ácido-básico (pH 7,41 y bicarbonato 20 mEq/l) e hidroelectrolítico (sodio 147 mEq/l, potasio 3,5 mEq/l) y la creatinina descendió a 5,5 mg/dl. Al tercer día de ingreso, por la presencia de deposiciones mucosas repetidas, se realizó una colonoscopia que puso de manifiesto una formación polipoidea sésil situada junto al esfínter anal y de 14 cm de longitud. La muestra endoscópica fue informada como adenoma velloso de recto. Al séptimo día de ingreso la enferma fue extubada, y dos días más tarde fue trasladada a planta para extirpación del adenoma\")\n",
        "#pred = token_classifier(\"Hombre de 38 años. Ingresó a la UCI (14/IX/ 2000), en postquirúrgico inmediato por heridas múltiples por arma de fuego en miembro superior derecho y abdomen. Hemicolectomía derecha con anastomosis termino-terminal y drenaje de hemoperitoneo (2000 cc.). Trece horas después, fue reintervenido por hipotensión y anemia, drenándose un hemoperitoneo de 3.000 cc. Bajo la sospecha de coagulopatía se realizó 48 horas de empaquetamiento y posteriormente malla de Velcro. El paciente presentó acidosis metabólica, insuficiencia renal aguda (el día 17, en remisión el 18) y coagulación intravascular diseminada.Fiebre el 17, 18 y 19. El 19 se llevó a un lavado abdominal (cierre fallido). Requirió ventilación mecánica desde el postquirúrgico hasta el 18 y se reinició el 19.Paraclínicos: Sep 17: Hb 7.8 gm/dl. Sep 18: leucocitos: 6.600, hipomagnesemia. Sep 19: hipofosfatemia (0.9 meq/lt). Sep 20: creatinina normal, hipofosfatemia.Medicación: Sep 18: Suspendida sedación (se inició en el postquirúrgico), recibe Ranitidinay Morfina. Septiembre 19: suspenden Morfina, reinician sedación bajo ventilación mecánica. Corrección de hipofosfatemia.\\n\\nDescripción y tratamiento de las alteraciones del comportamiento\\n18 de septiembre: obedece órdenes sencillas. Presentó agitación leve, poca colaboración yconfusión. Se le diagnosticó un delirium para el cual se le formulo Haloperidol, la primeradosis se le suministró a las 17:00 horas 1 mg. I.V. y luego se repitió cada 8 horas.Septiembre 19: igual dosis de Haloperidol.Sep 20: fue desintubado con agitación motora severa y confuso, se aumentó la dosis deHaloperidol a 2 mg c/8 horas I.V. Al no haber control de la alteración se incrementó elHaloperidol a 3 mg cada 4 horas junto con Midazolam 2mg (5 bolos). Ante la no mejoríase le administró Fenergan 50mg I.M. e infusión de Haloperidol 2mg/cada hora. Ante lasituación se hizo IC a Psiquiatría de Enlace.El psiquiatra encontró que tenía una historia de consumo de alcohol semanal. Personalidadprevia: ansioso, íaceleradoî, sin antecedentes claros de otra enfermedad diferente a abusode alcohol. Los informantes eran poco confiables porque no vivían continuamente con él(exesposa e hija). En esa fecha los datos positivos del exámen mental fueron los siguientes: inquietud, con evidencia de alucinaciones visuales, desorientación parcial en persona, lugar, tiempo y enfermedad; inmovilizado.Se diagnóstica delirium y se comienza a descartar un sindrome de abstinencia a alcohol uotros psicotóxicos. Se continuó el tratamiento con Haloperidol 10 mg I.V. cada 20 minutos,hasta alcanzar un total de 80mg. Se solicitó tomografía cerebral informada normal; se hizocorrección de electrolitos (hiponatremia: 138); las pruebas hepáticas fueron normales. Comola agitación persistía, se incrementó el Haloperidol hasta 180 mg junto con 5 bolos de 2 mgde Midazolam. Como no se logró controlar la agitación, se le suministró infusión de PROPOFOL (anestésico endovenoso) 120 mg, logrando control del cuadro clínico.Septiembre 21: disnea con infiltrado alveolar. Hipomagnesemia. En el liquido peritoneal seencontró Serratia Marcenses y Stafilococo Aureus. Delirium mejor: orientado en todas lasáreas. Refiere consumo de una botella semanal de alcohol.Se continuó con 90 mg. I.V. díarios de Haloperidol (15 mg cada 4 horas), Loracepam 1mgcada 6 horas V.O. Se suspende ranitidina porque puede agravar el delirium.Septiembre 22: se disminuye Haloperidol 10 mg c/4 horas I.V. El cultivo del líquido peritoneal positivo con resistencia a Cefotaxime, se inicia Ciprofloxacina, Vancomicina. Teníainfiltrados alveolares, fiebre, derrame pleural. Exámen mental: orientado, describe el trauma, refiere dificultades para tolerar la frustración, se considera como diagnóstico un posible Trastorno de la Personalidad. Se suspende Haloperidol y se deja Lorazepam 1 mgcada 12 horas, vía oral.Septiembre 23: sale de la UCI a habitación corriente.Septiembre 25: informa que es consumidor habitual de alcohol y cocaína. Se autoriza salida de la institución\")\n",
        "#pred = token_classifier(\"Niña de 4 años, sin antecedentes de interés, que consulta por tumefacción cervical izquierda dolorosa y fiebre (38oC), de pocas horas de evolución. El día anterior, tras quejarse de dolor a nivel occipital, lo padres observaron una garrapata en cuero cabelludo que retiraron manualmente. Tres días antes, la niña había estado en una zona rural en contacto con animales.\\n\\nEn la exploración física, se observa sobre la zona de picadura de la garrapata, en región parietoccipital izquierda, una placa eritematosa de 1 cm de diámetro con escara central, tumefacción cervical ipsilateral dolorosa, sin exantemas, siendo el resto de exploración normal. Placa de 1 cm de diámetro, con escara necrótica central tras picadura de garrapata.\\n\\nSe realiza hemograma y bioquímica con resultado normal, sin elevación de reactantes de fase aguda, y ecografía cervical, que muestra adenopatías de características inflamatorias, de predominio en región laterocervical izquierda, no abcesificadas, siendo la mayor de 3,2 x 1,2 cm. Ecografía cervical. Adenopatía de 3,2 x 1,2 cm, de características inflamatorias y no abcesificada.\\n\\nEvolución\\nSe sospechó un cuadro de linfadenopatía transmitida por garrapata o TIBOLA (de su acrónimo inglés Tick-Borne Lymphadenopathy). Se pautó tratamiento con doxiciclina oral (5 mg/kg/día cada 12 horas) en una pauta corta de 2 días. Paciente quedo afebril en las primeras 24 horas, con disminución progresiva de la adenitis cervical hasta quedar asintomáticas. Se realizó serología al diagnóstico y a las 6 semanas frente a Rickettsia conorii y Borrelia burdorferi (únicas serologías disponibles en nuestra área) con resultado negativo.\\n\\nDentro de las numerosas zoonosis cuyo vector es la garrapata, es importante conocer las manifestaciones de aquellas que son más frecuentes en nuestro país. Entre estas, destaca la linfadenopatía transmitida por garrapata o TIBOLA. Esta entidad se engloba dentro del grupo de enfermedades conocidas como Fiebres Manchadas ocasionadas por bacterias del genero Rickettsia (cocobacilos gram negativos intracelulares) y transmitidas por garrapatas. El agente principal aislado, en estos casos, es la Rickettsia slovaca, si bien, se han aislado otros patógenos, como Rickettsia raoultii, Rickettsia riojay otras bacterias, en pacientes con la misma clínica. Los vectores son las garrapatas del género Dermacentor (Dermacentor marginatusen los países mediterráneos, y Dermacentor reticularis en el Centro y Este de Europa). En los últimos años, TIBOLA, que también se conoce como DEBONEL (Dermacentor-borne necrosis erythema Lymphadenopathy) o SENLAT (Scalp eschar with neck lymphadenopathy after a tick bite), tiene una incidencia mayor que la fiebre botonosa mediterránea (FBM); rickettsiosis, con la que se establece el principal diagnóstico diferencial de TIBOLA.\")\n",
        "#pred = token_classifier(\"La madre del paciente neonatal es una mujer embarazada de 34 años que vive cerca del mercado mayorista de marisco de Huanan (a unos 1,2 km de distancia), en Wuhan. No ha visitado el mercado durante su embarazo y su familia no tiene casos confirmados ni presuntos de COVID-19, pero en la misma comunidad en la que vive se han diagnosticado más de 15 personas. Tiene antecedentes de hipotiroidismo de 4 años de evolución y se ha tratado con fármacos por vía oral; no tiene antecedentes de hipertensión, diabetes ni cardiopatías. Tuvo un aborto en 2016 a causa de alteraciones cromosómicas. Es alérgica a la penicilina y a las cefalosporinas de primera generación (positivo en pruebas cutáneas).\\n\\nA las 20:00 h del 1 de febrero de 2020, la mujer, de 40 semanas de gestación, presentó una pequeña hemorragia vaginal y dolor en la región abdominal inferior. Dos horas después, presentó fiebre (37,8 °C) y acudió al centro de asistencia maternoinfantil de Wuhan. Como tenía fiebre, fue derivada al consultorio de enfermedades infecciosas del hospital Tongji de Wuhan a la mañana siguiente. Una TAC torácica mostró opacidades de vidrio esmerilado en los lóbulos superior e inferior izquierdos, lo que indicaba la posibilidad de neumonía vírica.\\n\\nTAC torácica de la madre, obtenida el 2 de febrero de 2020, que muestra signos de infección en los lóbulos inferior y superior izquierdos e indica la posibilidad de neumonía vírica, con enfisema reducido en el lóbulo inferior derecho y una pequeña afectación en el lóbulo medio derecho.\\n\\nLos análisis de sangre mostraron linfocitopenia (0,97 × 109 células/L [normal: 1,1–3,2 × 109 células/L]), neutrofilia (9,97 × 109 células/L [normal: 1,8–6,3 × 109 células/L]) y concentraciones altas de proteína C-reactiva (11,5 mg/L [normal: < 1 mg/L]). Se decidió hospitalizarla por presunta neumonía vírica.\\n\\nAl ingreso, su temperatura era de 37,8 °C, la presión arterial de 131/89 mmHg, la frecuencia respiratoria de 20 r.p.m. y el pulso de 96 l.p.m. No presentaba tos ni expectoración. El pulso fetal era de 136 l.p.m. y su registro no mostró anomalías. Se realizó una cesárea de urgencia. Intraoperatoriamente se observó líquido amniótico con meconio. A las 8:45 la paciente dio a luz un niño con un peso de 3025 g. Los índices de Apgar a 1 y 5 minutos fueron de 8 y 9, respectivamente. El niño no regurgitó tras el parto. La piel era rojiza y el lloro, alto. La madre llevó una mascarilla N95 durante la intervención y, tras el alumbramiento, el niño no tuvo contacto con la madre. El niño se transfirió a la planta de neonatología 10 minutos después del parto para estrecha vigilancia; la madre se transfirió a la planta de enfermedades infecciosas para su aislamiento tras la intervención.\\n\\nMedia hora después del parto, el niño vomitó una vez tras ser alimentado con leche artificial, y se consideró que tenía disfagia. Tras un lavado gástrico, el niño pudo ser alimentado sin complicaciones. Los análisis de sangre del recién nacido mostraron linfocitopenia (2,43 × 109 células/L [normal: 3–8 × 109 células/L]), pruebas funcionales hepáticas alteradas (aspartato-aminotransferasa 143 U/L [normal: ≤  41 U/L]; bilirrubina total 33,0 μmol/L [normal: ≤ 26 μmol/L]; bilirrubina indirecta 26,0 μmol/L [normal: ≤ 16,8 μmol/L]) y alta concentración de creatina-cinasa (479 U/L [normal: ≤  41 U/L]). Se administró penicilina G (150.000 U una vez por día, bolo intravenoso) y vitamina K1 (1 mg una vez por día, i.v.) como profilaxis antibiótica y para evitar coagulopatías, respectivamente.\\n\\nLa madre permaneció en buen estado y afebril durante el periodo posoperatorio inmediato. No presentó tos ni ninguna otra molestia, como diarrea, náuseas o vómitos. Sus constantes vitales fueron estables, con una saturación de oxígeno del 99%. Se le administró un tratamiento antivírico, con 40 μg de interferón α1b humano recombinante atomizado por vía inhalatoria con 2 mL de solución de esterilización dos veces por día y ganciclovir (0,25 g cada 12 horas, i.v.). También se le administró abipenem (0,3 g cada 12 horas, i.v.) y moxifloxacina (0,4 g una vez por día, i.v.) para prevenir infecciones. La madre tuvo fiebre intermitente durante el primer día del posoperatorio, llegando a 38,3 °C; se le administró metilprednisolona (20 mg i.v.). Su frotis faríngeo para detección del SARS-CoV-2 resultó positivo ese mismo día. Inmediatamente, se obtuvo un frotis faríngeo del recién nacido (36 horas tras el parto) junto con leche de la madre. Recomendamos a la madre no amamantar al niño y extraerse leche para evitar mastitis.\\n\\nLa respuesta neurológica del recién nacido resultó aceptable durante el primer día después del parto y su saturación de oxígeno se mantuvo > 92% sin oxigenoterapia. Las pruebas analíticas del niño fueron negativas para Legionella pneumophila, Chlamydia pneumoniae, Mycoplasma pneumoniae, Rickettsia, adenovirus, virus respiratorio sincicial, virus de la gripe A virus de la gripe B y virus paragripal 1–3.\\n\\nEl 4 de febrero, el segundo día posoperatorio, las constantes vitales de la madre eran estables y se le administró prednisolona (40 mg una vez por día i.v.). El recién nacido se mantuvo sano y su gasometría mostró pH de 7,476↑, presión parcial de dióxido de carbono de 28,2 mm Hg↓, presión parcial de oxígeno de 116,0 mm Hg↑, bicarbonato de 20,6 mmol/L↓, exceso de base de 1,30 mmol/L y saturación de oxígeno periférico de 98,4%. Las pruebas para un conjunto de virus pediátricos resultaron negativas para citomegalovirus, virus de la rubéola, Toxoplasma gondii, virus del herpes común tipos 1 y 2, ecovirus, parvovirus B19, virus de Epstein-Barr, virus de Coxsackie A16, virus de Coxsackie B, virus del sarampión y virus de la varicela zóster. La TAC torácica del recién nacido mostró un engrosamiento de la textura de los pulmones sin anormalidades cardíacas. TAC torácica del recién nacido, obtenida el 4 de febrero de 2020, que muestra un engrosamiento de la textura de los pulmones sin anormalidades cardíacas. Se alimentó al niño con leche artificial, 25 mL cada 3 horas, y se supervisó estrechamente.\\n\\nEl 5 de febrero, las constantes vitales del recién nacido eran estables, con una saturación de oxígeno por encima del 90% y sin molestias como apnea o vómitos. El resultado del frotis faríngeo para detección del SARS-CoV-2 fue positivo a las 36 horas después del parto. Combinando todas las pruebas analíticas y un intercambio exhaustivo de ideas, diagnosticamos que el niño presentaba infección por SARS-CoV-2. Como el departamento neonatal del Hospital Tingji no dispone de las condiciones de aislamiento para el recién nacido, se transfirió al Hospital Maternoinfantil de Wuhan ese mismo día, para un mejor aislamiento. Tras hallar las pruebas de la infección neonatal, efectuamos pruebas de ácido nucleico del SARS-CoV-2 en la sangre del cordón umbilical y muestras de la placenta que habíamos conservado durante la intervención; los resultados fueron negativos. La muestra de la leche materna también fue negativa para SARS-CoV-2.\\n\\nHicimos un seguimiento del estado del recién nacido después de ser transferido al Hospital Maternoinfantil de Wuhan. Su estado era bueno y afebril, sin tos ni vómitos. Fue supervisado estrechamente en condiciones de aislamiento y no se le administró ningún tratamiento especial. Una TAC torácica el 6 de febrero mostró sombras nodulares de alta densidad bajo la pleura del segmento posterior del lóbulo superior del pulmón derecho. En una TAC torácica del 12 de febrero se observaron pequeños núcleos de sombras parcheadas en los lóbulos inferior y superior del pulmón derecho. En una TAC torácica del 17 de febrero se observaron unos pocos y pequeños núcleos de sombras parcheadas en los lóbulos inferior y superior del pulmón derecho, absorbidas en comparación con las anteriores. El 17 de febrero de 2020, las pruebas de ácido nucleico de frotis faríngeos y anales para detección del SARS-CoV-2 resultaron negativas. El recién nacido fue dado de alta el 18 de febrero de 2020.\\n\")\n",
        "#pred = token_classifier(\"Mujer de 78 años, diagnosticada en 1978 de SSP por un síndrome seco (xerostomía y xeroftalmia), con biopsia de glándula salivar menor y pruebas de Schirmer y Rosa Bengala positivas.\")\n",
        "#pred = token_classifier(\"Paciente mujer de 84 años diagnosticada de artritis reumatoide, que ingresó de urgencia por dolor y distensión abdominal. Con el diagnóstico de íleo suboclusivo se instauró inicialmente tratamiento médico. Sin ningún antecedente urológico, comenzó a las pocas horas del sondaje uretral con hematuria, que se hizo muy intensa, evolucionando a la formación de un gran coágulo vesical que ocupaba toda la cavidad, observando además en la tomografía axial computarizada líquido y gas perivesical. Se procedió a intervención quirúrgica urgente, observando un tramo de íleon de 1,5 m de longitud hasta 10 cm de la válvula ileocecal, de aspecto violáceo edematoso, la cual se recupera adquiriendo aspecto, coloración y peristaltismo normales; presentaba una pequeña fisura en la pared vesical, por lo que se le practicó una cistotomía con la que se drena el gran coágulo, observando sangrado en sábana de la pared y gran friabilidad de la misma, tomando biopsias múltiples y realizando posteriormente ligadura de ambas hipogástricas. En el postoperatorio inmediato, tras un cuadro de anuria y alteración hemodinámica severa, llegó al exitus (09/05/2000). El diagnóstico anatomopatológico reveló que todas las biopsias vesicales que fueron practicadas tenían depósito amiloide (AA) vascular e intersticial.\")\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL4mdo1umfTJ"
      },
      "outputs": [],
      "source": [
        "test_path = \"/content/drive/MyDrive/Datasets/test_background/text_files/distemist_test_\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF2yE2iJtAJy"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "with open(test_path + str(i) + \".txt\", \"r\", encoding=\"UTF-8\") as ftest:\n",
        "  pred = token_classifier(ftest.read())\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-Processing"
      ],
      "metadata": {
        "id": "5SXdOl-E6Qk6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blQLws4pLuBP"
      },
      "outputs": [],
      "source": [
        "def grouping_entities(pred):\n",
        "  import re\n",
        "  output = []\n",
        "  for e in pred:\n",
        "    if \"##\" not in e['word']:\n",
        "      output.append(e)\n",
        "    else:\n",
        "      try:\n",
        "        if e['start'] == (output[-1]['end']):\n",
        "          output[-1]['word'] = output[-1]['word']+re.sub(\"##\",\"\",e['word'])\n",
        "          output[-1]['end'] = e['end']\n",
        "      except:\n",
        "        pass\n",
        "    \n",
        "    try:\n",
        "      if (e['entity_group'] == \"B\" or e['entity_group'] == \"I\") and (e['start'] == (output[-2]['end']+1)):\n",
        "        output[-2]['word'] = output[-2]['word']+\" \"+e['word']\n",
        "        output[-2]['end'] = e['end']\n",
        "        output.pop(-1)\n",
        "    except:\n",
        "      pass\n",
        "    \n",
        "    try:\n",
        "      if e['start'] == (output[-2]['end']):\n",
        "        output[-2]['word'] = output[-2]['word']+e['word']\n",
        "        output[-2]['end'] = e['end']\n",
        "        output.pop(-1)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hPi30NgqtDQ"
      },
      "outputs": [],
      "source": [
        "grouping_entities(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZwOFHailsVL"
      },
      "source": [
        "## Predictions on test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D_RSE3ulwJw"
      },
      "outputs": [],
      "source": [
        "print(\"Processing...\")\n",
        "import re\n",
        "f = open(\"/content/drive/MyDrive/distemist_subtrack1_test_predictions_NER_EHR_Spanish_model_Mulitlingual_BERT.tsv\", \"w\", encoding=\"UTF-8\")\n",
        "#f.write(\"filename\\tmark\\tlabel\\toff0\\toff1\\tspan\\n\")\n",
        "f.write(\"filename\\tlabel\\toff0\\toff1\\tspan\\n\")\n",
        "for i in range(1,3001):\n",
        "  print(f\"Text: {i}\", end=\"\\r\")\n",
        "  with open(test_path + str(i) + \".txt\", \"r\", encoding=\"UTF-8\") as ftest:\n",
        "    hc = ftest.read()\n",
        "    pred = token_classifier(hc)\n",
        "    pred_grouped = grouping_entities(pred)\n",
        "    t = 1\n",
        "    for p in pred_grouped:\n",
        "\n",
        "      off0 = int(p['start'])\n",
        "      off1 = int(p['end'])\n",
        "      span = hc[off0:off1]\n",
        "\n",
        "      if span in [\".\", \",\", \";\", \":\", '\"', \"-\", \"a\", \"de\", \"por\", \"in\", \"que\", \"da\", \"di\", \"se\", \"Las\", \"re\", \"sin\"]:\n",
        "        continue\n",
        "\n",
        "      if \"\\n\" in span:\n",
        "        span = re.sub(\"\\n\",\" \",span)\n",
        "\n",
        "      if \" - \" in span:\n",
        "        span = re.sub(\" - \",\"-\",span)\n",
        "        off1 = off1-2\n",
        "\n",
        "      if \"( \" in span:\n",
        "        span = re.sub(\"\\( \",\"(\",span)\n",
        "        off1 = off1-1\n",
        "\n",
        "      if \" )\" in span:\n",
        "        span = re.sub(\" \\)\",\")\",span)\n",
        "        off1 = off1-1\n",
        "\n",
        "      if span.endswith(\" y\") :\n",
        "        span = span[:-2]\n",
        "        off1 = off1-2\n",
        "\n",
        "      if span.endswith(\" de\") or span.endswith(\" en\"):\n",
        "        span = span[:-3]\n",
        "        off1 = off1-3\n",
        "\n",
        "      if span.endswith(\" por\") or span.endswith(\" con\"):\n",
        "        span = span[:-4]\n",
        "        off1 = off1-4\n",
        "\n",
        "      if span.endswith(\".\") or span.endswith(\",\") or span.endswith(\";\") or span.endswith(\":\") or span.endswith(\"–\") or span.endswith(\"-\"):\n",
        "        span = span[:-1]\n",
        "        off1 = off1-1\n",
        "\n",
        "      if span.endswith(\" .\") or span.endswith(\" ,\") or span.endswith(\" ;\") or span.endswith(\" :\") or span.endswith(\" –\") or span.endswith(\" -\"):\n",
        "        span = span[:-2]\n",
        "        off1 = off1-2\n",
        "\n",
        "      #f.write(\"distemist_test_\"+str(i)+\"\\t\"+\"T\"+str(t)+\"\\t\"+\"ENFERMEDAD\"+\"\\t\"+str(p['start'])+\"\\t\"+str(p['end'])+\"\\t\"+p['word']+\"\\n\")\n",
        "      #f.write(\"distemist_test_\"+str(i)+\"\\t\"+\"T\"+str(t)+\"\\t\"+\"ENFERMEDAD\"+\"\\t\"+str(off0)+\"\\t\"+str(off1)+\"\\t\"+span+\"\\n\")\n",
        "      f.write(\"distemist_test_\"+str(i)+\"\\t\"+\"ENFERMEDAD\"+\"\\t\"+str(off0)+\"\\t\"+str(off1)+\"\\t\"+span+\"\\n\")\n",
        "      #print(\"distemist_test_\"+str(i)+\"\\t\"+\"T\"+str(t)+\"\\t\"+\"ENFERMEDAD\"+\"\\t\"+str(p['start'])+\"\\t\"+str(p['end'])+\"\\t\"+p['word'])\n",
        "      t+=1\n",
        "f.close()\n",
        "print(\"Completo.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "NLP-CIC-WFU contribution to DisTEMIST shared task",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be10f0b198604969aa84276332067f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3d0bab880604cde8d9e247b49f884b1",
              "IPY_MODEL_3da695ee9bc94ba188a58f699f2f3b01",
              "IPY_MODEL_b13ea0e6e06840d8b93349a79a55581f",
              "IPY_MODEL_d61ef4c367a145ce9b725b878d3a9d8f",
              "IPY_MODEL_ca22d0f855de402fa96ff6f65d621d5d"
            ],
            "layout": "IPY_MODEL_e820970be81f4f4ea96cd885e0de9650"
          }
        },
        "b3d0bab880604cde8d9e247b49f884b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2381aa4ded5d4ef89360071abe08af5c",
            "placeholder": "​",
            "style": "IPY_MODEL_c49fe48bdb17407685afbd34b7153d60",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3da695ee9bc94ba188a58f699f2f3b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1e0c1d998e8b44fbae3fc14a988d43e8",
            "placeholder": "​",
            "style": "IPY_MODEL_bdc3b3f9f6734176b2fbbadd3150e303",
            "value": ""
          }
        },
        "b13ea0e6e06840d8b93349a79a55581f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ff36684af72c4705b106ba9b67665136",
            "style": "IPY_MODEL_610a7e46b1f144cc93e532518922becc",
            "tooltip": ""
          }
        },
        "d61ef4c367a145ce9b725b878d3a9d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffacec949e2040afac3fad216f3c5bc3",
            "placeholder": "​",
            "style": "IPY_MODEL_60595746ea1d46b49de2c3a6c73c879d",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. <br> <i>Logging in with your username and password is deprecated and\nwon't be possible anymore in the near future. You can still use them for now by\nclicking below.</i> </center>"
          }
        },
        "ca22d0f855de402fa96ff6f65d621d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Use password",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_608445951e32406aa3ad9ce9a29c357d",
            "style": "IPY_MODEL_a79468f630e041a1ba67f6d94bba26b3",
            "tooltip": ""
          }
        },
        "e820970be81f4f4ea96cd885e0de9650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "2381aa4ded5d4ef89360071abe08af5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c49fe48bdb17407685afbd34b7153d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e0c1d998e8b44fbae3fc14a988d43e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc3b3f9f6734176b2fbbadd3150e303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff36684af72c4705b106ba9b67665136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610a7e46b1f144cc93e532518922becc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ffacec949e2040afac3fad216f3c5bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60595746ea1d46b49de2c3a6c73c879d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "608445951e32406aa3ad9ce9a29c357d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79468f630e041a1ba67f6d94bba26b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f68660f7cf1a4f14b46807d4026aa137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0090194cbfe84036b23ba9d38bcf9161",
              "IPY_MODEL_9d1a091689054f71aa807f1408b86aa9",
              "IPY_MODEL_fbd8aeede62e47dbbf0559db51ce6b41"
            ],
            "layout": "IPY_MODEL_50a34c17a1e74e3aae1f49037e866a6c"
          }
        },
        "0090194cbfe84036b23ba9d38bcf9161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b51d0d7a0384e53950f44fb38fcb5ee",
            "placeholder": "​",
            "style": "IPY_MODEL_defda63cc410427e8e6e69e9e1300a56",
            "value": "100%"
          }
        },
        "9d1a091689054f71aa807f1408b86aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b4065e943884cdb8b47f31ecf7e2bc3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5c5d08df78c458bae2c1d1af42272c9",
            "value": 1
          }
        },
        "fbd8aeede62e47dbbf0559db51ce6b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feef01dd690049db8f4728a84ca14b49",
            "placeholder": "​",
            "style": "IPY_MODEL_12ef2e02cc9b4407b22b0ba7ec285829",
            "value": " 1/1 [00:01&lt;00:00,  1.10s/ba]"
          }
        },
        "50a34c17a1e74e3aae1f49037e866a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b51d0d7a0384e53950f44fb38fcb5ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "defda63cc410427e8e6e69e9e1300a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b4065e943884cdb8b47f31ecf7e2bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c5d08df78c458bae2c1d1af42272c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "feef01dd690049db8f4728a84ca14b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ef2e02cc9b4407b22b0ba7ec285829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "415065514b8c44f28c8b9b6d7e67fdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9902a89f99644d5daf8e99e44b283e5e",
              "IPY_MODEL_cfb2e475c10e45d4b851e895bc9b49bb",
              "IPY_MODEL_a39a848a5cc04157bddd97031807a3ed"
            ],
            "layout": "IPY_MODEL_1292e58708264469a50505ea9e36bd56"
          }
        },
        "9902a89f99644d5daf8e99e44b283e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8e0c4d04534d2b81ad2b93a0c82c29",
            "placeholder": "​",
            "style": "IPY_MODEL_9345205e5e40454a9816a04ad4756f8f",
            "value": "100%"
          }
        },
        "cfb2e475c10e45d4b851e895bc9b49bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6828783293ce4f0890f3d0056ffcd207",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b5dc760f653414083a00e24fe9a737b",
            "value": 1
          }
        },
        "a39a848a5cc04157bddd97031807a3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38bbf811b2848b1bcf50a99a8de912c",
            "placeholder": "​",
            "style": "IPY_MODEL_2779dee281b14a0f9d07e5f794ff9e1a",
            "value": " 1/1 [00:00&lt;00:00,  2.29ba/s]"
          }
        },
        "1292e58708264469a50505ea9e36bd56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a8e0c4d04534d2b81ad2b93a0c82c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9345205e5e40454a9816a04ad4756f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6828783293ce4f0890f3d0056ffcd207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b5dc760f653414083a00e24fe9a737b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f38bbf811b2848b1bcf50a99a8de912c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2779dee281b14a0f9d07e5f794ff9e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}