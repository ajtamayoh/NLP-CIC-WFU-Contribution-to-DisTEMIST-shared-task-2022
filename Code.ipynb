{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajtamayoh/NLP-CIC-WFU-Contribution-to-DisTEMIST-shared-task-2022/blob/main/Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP-CIC-WFU contribution to DisTEMIST 2022 sub-track 1 entities\n",
        "\n",
        "Here you are the source code for the paper:\n",
        "\n",
        "### mBERT and Simple Post-Processing: A Baseline for Disease Mention Detection in Spanish\n",
        "\n",
        "Authors:\n",
        "\n",
        "Antonio Tamayo (ajtamayo2019@ipn.cic.mx, ajtamayoh@gmail.com)\n",
        "\n",
        "Diego A. Burgos (burgosda@wfu.edu)\n",
        "\n",
        "Alexander Gelbulkh (gelbukh@gelbukh.com)\n",
        "\n",
        "For bugs or questions related to the code, do not hesitate to contact us (Antonio Tamayo: ajtamayoh@gmail.com)\n",
        "\n",
        "If you use this code please cite our work:\n",
        "\n",
        "Tamayo, A., Burgos, D. A., & Gelbukh, A. (2022). mbert and simple post-processing: A baseline for disease mention detection in spanish. In Working Notes of Conference and Labs of the Evaluation (CLEF) Forum. CEUR Workshop Proceedings.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nml9hXt1NHXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements\n",
        "\n",
        "To run this code you need to download the dataset (two folders: training and test_background) at: https://drive.google.com/drive/folders/1qJQQHdEkm6YMN-1KRUPfBx8lFQKUZK5Z?usp=sharing\n",
        "\n",
        "Then, you must create a folder called \"Datasets\" in the root of your Google Drive and load there both folders previously downloaded.\n",
        "\n",
        "Once the dataset is ready to use, you should [open this notebook in colab](https://colab.research.google.com/github/ajtamayoh/NLP-CIC-WFU-Contribution-to-DisTEMIST-shared-task-2022/blob/main/Code.ipynb) and save a copy in your drive."
      ],
      "metadata": {
        "id": "6S9L_KErP3yM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About the infrastructure"
      ],
      "metadata": {
        "id": "3gGu8XvkQuHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "9YCD8Yn8QvCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "PDijHzOMQzwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to Google drive"
      ],
      "metadata": {
        "id": "U64pk_flQ-nw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgzIfAnfaDR1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1ncKARiLoRQ"
      },
      "source": [
        "## Exploring & Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZaPi7EMLrz8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PLlHg0aLtGp"
      },
      "outputs": [],
      "source": [
        "distemist_track_1_training = pd.read_csv(\"/content/drive/MyDrive/Datasets/training/subtrack1_entities/distemist_subtrack1_training_mentions.tsv\", delimiter=\"\\t\")\n",
        "distemist_track_1_training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW058gNCnxMD"
      },
      "outputs": [],
      "source": [
        "list_off0 = list(distemist_track_1_training['off0'])\n",
        "list_off1 = list(distemist_track_1_training['off1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnhX_oQ5CJfh"
      },
      "outputs": [],
      "source": [
        "text_files_path = \"/content/drive/MyDrive/Datasets/training/text_files\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNIun4SYCzP5"
      },
      "outputs": [],
      "source": [
        "f = open(text_files_path + \"/\" + distemist_track_1_training.iloc[1,0] + \".txt\", \"r\", encoding=\"UTF-8\")\n",
        "for l in f:\n",
        "  print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhs3W80KM7ZG"
      },
      "outputs": [],
      "source": [
        "#Clinical cases\n",
        "HCs = {}\n",
        "for fname in distemist_track_1_training[\"filename\"]:\n",
        "  with open(text_files_path + \"/\" + fname + \".txt\", \"r\", encoding=\"UTF-8\") as f:\n",
        "    HCs.update({fname: f.read()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPDGRBTdLw_W"
      },
      "outputs": [],
      "source": [
        "len(HCs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOVeEVPjLIM5"
      },
      "outputs": [],
      "source": [
        "#This code cell is optional. Uncomment it if you want to create a small development partition\n",
        "'''\n",
        "dev_files = [\"es-S1130-14732006000500005-1\", \"es-S1130-14732005000200003-1\", \"es-S1130-05582014000200008-1\", \"es-S0365-66912010000600004-1\", \"es-S0212-71992004000600005-1\", \"es-S0211-57352011000100008-1\", \"es-S0210-48062009000600016-1\", \"es-S0004-06142009000200008-1\", \"es-S0004-06142007000600016-2\"]\n",
        "#Se descomenta para tener un dataset de development y observar las métricas con el script de la competencia\n",
        "for f in dev_files:\n",
        "  HCs.pop(f)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0xkvhzkL0g9"
      },
      "outputs": [],
      "source": [
        "len(HCs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D_CPkKjsCzz"
      },
      "outputs": [],
      "source": [
        "#Diseases\n",
        "ENF = {}\n",
        "enfermedades = []\n",
        "fn = distemist_track_1_training[\"filename\"][0]\n",
        "for fname, enf in zip(distemist_track_1_training[\"filename\"], distemist_track_1_training[\"span\"]):\n",
        "    if fname!=fn:\n",
        "      enfermedades = []\n",
        "    enfermedades.append(enf)\n",
        "    ENF.update({fname: enfermedades})\n",
        "    fn = fname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-aDUgrHULAi"
      },
      "outputs": [],
      "source": [
        "len(ENF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMYj6Vo6MNzB"
      },
      "outputs": [],
      "source": [
        "#This code cell is optional. Uncomment it if you want to create a small development partition. This works together with the cell above with a similar comment.\n",
        "'''\n",
        "#Se descomenta para tener un dataset de development y observar las métricas con el script de la competencia\n",
        "for f in dev_files:\n",
        "  ENF.pop(f)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4xf4L3nMQDK"
      },
      "outputs": [],
      "source": [
        "len(ENF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNRlMovPn5mi"
      },
      "outputs": [],
      "source": [
        "HCs[\"es-S1139-76322015000300009-1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjmYjm_u7LBl"
      },
      "outputs": [],
      "source": [
        "ENF[\"es-S0210-56912007000900007-3\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization using SpaCy"
      ],
      "metadata": {
        "id": "4ZSJ6gatRc9r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocmTmRkiLtJM"
      },
      "outputs": [],
      "source": [
        "from spacy.lang.es import Spanish\n",
        "nlp = Spanish()\n",
        "# Create a Tokenizer with the default settings for Spanish\n",
        "# including punctuation rules and exceptions\n",
        "tokenizer_spacy = nlp.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orQHlLHJM7b3"
      },
      "outputs": [],
      "source": [
        "HCs_tokenized = []\n",
        "for hc in HCs:\n",
        "    hl = []\n",
        "    tokens = tokenizer_spacy(HCs[hc])\n",
        "    #tokens = HCs[hc].split(\" \") #The simplest option. It was not used in our work.\n",
        "    for t in tokens:\n",
        "        hl.append(str(t))\n",
        "    HCs_tokenized.append(hl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rClFCgxnM7e4"
      },
      "outputs": [],
      "source": [
        "len(HCs_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0v803fyUFSM"
      },
      "outputs": [],
      "source": [
        "#HCs_tokenized[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xE2NudYNHey"
      },
      "outputs": [],
      "source": [
        "Ent_tokenized = []\n",
        "for enf in ENF:\n",
        "    Tks = []\n",
        "    for e in ENF[enf]:\n",
        "      sl = []\n",
        "      tokens = tokenizer_spacy(e)\n",
        "      #tokens = e.split(\" \")\n",
        "      for t in tokens:\n",
        "          sl.append(str(t))\n",
        "      Tks.append(sl)\n",
        "    Ent_tokenized.append(Tks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMuPfY-XNHh4"
      },
      "outputs": [],
      "source": [
        "len(Ent_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR--IobbNHj6"
      },
      "outputs": [],
      "source": [
        "Ent_tokenized[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQu4uagdNePZ"
      },
      "source": [
        "## Tagging Data with BIO scheme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKy-FSGdiWhY"
      },
      "outputs": [],
      "source": [
        "def find_idx(list_to_check, item_to_find):\n",
        "    indices = []\n",
        "    for idx, value in enumerate(list_to_check):\n",
        "        if value == item_to_find:\n",
        "            indices.append(idx)\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsuGnvZMNYX2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "labels_tokenized = []\n",
        "idx =-1\n",
        "for hct, et in zip(HCs_tokenized, Ent_tokenized):\n",
        "    idx+=1\n",
        "    labels = []\n",
        "    for i in range(len(hct)):\n",
        "        #Labels: 0->'O'; 1->'B'; 2->'I'\n",
        "        #labels.append('O')\n",
        "        labels.append(0)\n",
        "\n",
        "    #For Entities (Diseases|Enfermedades)\n",
        "    for enf in et:\n",
        "      first = True\n",
        "      for e in enf:\n",
        "          if first == True:\n",
        "              try:\n",
        "                #labels[hct.index(e)] = 'B'\n",
        "                #labels[posLab] = 'B'\n",
        "                indices = find_idx(hct, e)\n",
        "                if len(indices) > 1:\n",
        "                  for id in indices:\n",
        "                      labels[id] = 1\n",
        "                else:\n",
        "                  labels[hct.index(e)] = 1\n",
        "\n",
        "                first = False\n",
        "              except:\n",
        "                first = False\n",
        "                if e == \"sarcoma+carcinoma\" or e == \"carcinoma+sarcoma\":\n",
        "                  continue\n",
        "                print(hct)\n",
        "                print(et)\n",
        "                print(enf)\n",
        "                print(e)\n",
        "                print(idx)\n",
        "                sys.exit(0)\n",
        "          else:\n",
        "              try:\n",
        "                #labels[hct.index(e)] = 'I'\n",
        "                #labels[posLab] = 'I'\n",
        "                indices = find_idx(hct, e)\n",
        "                if len(indices) > 1:\n",
        "                  for id in indices:\n",
        "                      if labels[id-1] != 0:\n",
        "                        labels[id] = 2\n",
        "                else:\n",
        "                  labels[hct.index(e)] = 2\n",
        "              except:\n",
        "                if e == \"sarcoma+carcinoma\" or e == \"carcinoma+sarcoma\":\n",
        "                  continue\n",
        "                print(hct)\n",
        "                print(et)\n",
        "                print(enf)\n",
        "                print(e)\n",
        "                print(idx)\n",
        "                sys.exit(0)\n",
        "\n",
        "    labels_tokenized.append(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo_WB3uUWmlK"
      },
      "outputs": [],
      "source": [
        "j = 0\n",
        "for i in range(len(HCs_tokenized[j])):\n",
        "  print(str(HCs_tokenized[j][i]) + \"\\t\" + str(labels_tokenized[j][i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0OdnKiDSCn-"
      },
      "source": [
        "## Validating tokenization and alignment with the BIO tags.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61hktW4PR-bt"
      },
      "outputs": [],
      "source": [
        "flag = 0\n",
        "for st, lt in zip(HCs_tokenized, labels_tokenized):\n",
        "    if len(st) != len(lt):\n",
        "        print(st)\n",
        "        print(lt)\n",
        "        flag = 1\n",
        "if flag==0:\n",
        "    print(\"Everything is aligned!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence tokenization is an alternative but we finally used the whole clinical cases as samples."
      ],
      "metadata": {
        "id": "fPDzmJE6Wgho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeFfLm3Ubu7x"
      },
      "outputs": [],
      "source": [
        "sent_tokenized = []\n",
        "label_sent_tokenized = []\n",
        "for ht, lht in zip(HCs_tokenized, labels_tokenized):\n",
        "  st = []; lbst = []\n",
        "  for h, l in zip(ht,lht):\n",
        "    if h != \".\":\n",
        "      st.append(h)\n",
        "      lbst.append(l)\n",
        "    else:\n",
        "      st.append(\".\")\n",
        "      lbst.append(0)\n",
        "      sent_tokenized.append(st)\n",
        "      label_sent_tokenized.append(lbst)\n",
        "      st = []; lbst = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT7Ig0bcmOQR"
      },
      "outputs": [],
      "source": [
        "len(sent_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czWqzs_pmch5"
      },
      "outputs": [],
      "source": [
        "sent_tokenized[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOsSFm0wmS2I"
      },
      "outputs": [],
      "source": [
        "len(label_sent_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx6NtMpxmg2N"
      },
      "outputs": [],
      "source": [
        "label_sent_tokenized[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RIR3iRCUc0h"
      },
      "source": [
        "# Disease mentions identification as a Token classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WaBFjAEUc0l"
      },
      "source": [
        "## Install the Transformers and Datasets libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEX7xfLiUc0m"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the followin line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Authentication\n",
        "\n",
        "If you want to save your own model and make it available online we strongly recommend signing up at: https://huggingface.co/"
      ],
      "metadata": {
        "id": "K90ROU-SaLC5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgxCB7y8Uc0n"
      },
      "source": [
        "You will need to setup git, adapt your email and name in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hstit1gRUc0o"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"your_email\"\n",
        "!git config --global user.name \"your_name\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXbs9i1fUc0o"
      },
      "source": [
        "You will also need to be logged in to the Hugging Face Hub. Execute the following and enter your credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6SkGUEUUc0p"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9FTB991Sl12"
      },
      "source": [
        "## Building the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KVP5DQ7ZLuG"
      },
      "outputs": [],
      "source": [
        "dic = {\"tokens\": HCs_tokenized, \"ner_tags\": labels_tokenized} #For the whole clinical case. We used this option for our paper.\n",
        "#dic = {\"tokens\": sent_tokenized, \"ner_tags\": label_sent_tokenized} #Use this option if you want to check the model performance with sentences tokenized by \". \" but the whole clinical cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZawOY4qqSoz6"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "dataset = Dataset.from_dict(dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTBNV4yzYuzc"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMZbF0mSaOiS"
      },
      "outputs": [],
      "source": [
        "#For training, validation, and test partitions\n",
        "\"\"\"\n",
        "#Train, val, test partitions\n",
        "train_test = dataset.train_test_split()\n",
        "test_val = train_test['test'].train_test_split()\n",
        "raw_datasets = DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'validation': test_val['train'],\n",
        "    'test': test_val['test']\n",
        "    })\n",
        "\"\"\"\n",
        "\n",
        "#Just for training and validation partitions\n",
        "train_test = dataset.train_test_split()\n",
        "raw_datasets = DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'validation': train_test['test']\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFQfd5u9Uc0q"
      },
      "outputs": [],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI0wWv0aUc0t"
      },
      "outputs": [],
      "source": [
        "raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "#raw_datasets[\"train\"][0][\"pos_tags\"]\n",
        "#raw_datasets[\"train\"][0][\"chunk_tags\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-usgjZalK7E9"
      },
      "outputs": [],
      "source": [
        "raw_datasets['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLHqEaOVUc0u"
      },
      "outputs": [],
      "source": [
        "label_names = ['O','B','I']\n",
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iCYOiwZUc0u"
      },
      "outputs": [],
      "source": [
        "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
        "labels = [int(n) for n in raw_datasets[\"train\"][0][\"ner_tags\"]]\n",
        "#labels = raw_datasets[\"train\"][0][\"pos_tags\"]\n",
        "#labels = raw_datasets[\"train\"][0][\"chunk_tags\"]\n",
        "line1 = \"\"\n",
        "line2 = \"\"\n",
        "for word, label in zip(words, labels):\n",
        "    full_label = label_names[label]\n",
        "    max_length = max(len(word), len(full_label))\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "print(line1)\n",
        "print(line2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading mBERT as a pre-trained model"
      ],
      "metadata": {
        "id": "CRKUqAVVbvf7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuZTRxLPUc0v"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-multilingual-cased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr7qjUe7Uc0v"
      },
      "outputs": [],
      "source": [
        "tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbchCgPGUc0v"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
        "inputs.tokens()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udiVaGenUc0w"
      },
      "outputs": [],
      "source": [
        "inputs.word_ids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhu4Cl3-Uc0w"
      },
      "outputs": [],
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            # If the label is B-XXX we change it to I-XXX\n",
        "            if label % 2 == 1:\n",
        "                label += 1\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H820wg0sUc0x"
      },
      "outputs": [],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-ZxnhGSUc0x"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INNjCms4Uc0y"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFpUXjvmUc0y"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHCuXD5EUc0y"
      },
      "outputs": [],
      "source": [
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6GW37IPUc0z"
      },
      "outputs": [],
      "source": [
        "for i in range(2):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImHtQb6HUc0z"
      },
      "outputs": [],
      "source": [
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDjn2La4Uc0z"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mqjInn4Uc0z"
      },
      "outputs": [],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "labels = [label_names[i] for i in labels]\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIaLt4n-Uc00"
      },
      "outputs": [],
      "source": [
        "predictions = labels.copy()\n",
        "predictions[2] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xewJhf6Uc00"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdmwR_2HUc00"
      },
      "outputs": [],
      "source": [
        "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svP0J1bWs3pK"
      },
      "outputs": [],
      "source": [
        "id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvIvq5wxs8P8"
      },
      "outputs": [],
      "source": [
        "label2id"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing the head of prediction for Disease Mentions Identification under the BIO scheme"
      ],
      "metadata": {
        "id": "FKNvor68cVQs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9Rrve75Uc00"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    num_labels = 3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDiAYqsYUc00"
      },
      "outputs": [],
      "source": [
        "model.config.num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS-L0U1XUc01"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"NLP-CIC-WFU_DisTEMIST_fine_tuned_bert-base-multilingual-cased\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning mBERT for Disease mentions identification"
      ],
      "metadata": {
        "id": "tdHv4CMvctoB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvHls_JJUc01"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the fine-tuned model at Hugging Face (It requires previous authentication)"
      ],
      "metadata": {
        "id": "0rGdJ42qc3sh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAvTQZClUc01"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(commit_message=\"Training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "485I5jdmd6Dr"
      },
      "source": [
        "## Analyzing predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk5cSus7d5cA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1puArlhRe7_o"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "print(raw_datasets[\"validation\"][i]['tokens'])\n",
        "for j in range(len(preds[i])):\n",
        "  print(raw_datasets[\"validation\"][i]['ner_tags'][j], \"\\t\", preds[i][j])\n",
        "print(' '.join(raw_datasets[\"validation\"][i]['tokens']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjEM4d77Toxs"
      },
      "source": [
        "## Loading the model for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKO5fyKyUc04"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "#Replace this with your own checkpoint. If you have run all the previous cells successfully, the model should be available at your hugging face account with the name: NLP-CIC-WFU_DisTEMIST_fine_tuned_bert-base-multilingual-cased\n",
        "model_checkpoint = \"ajtamayoh/NER_EHR_Spanish_model_Mulitlingual_BERT\"\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr7QlXqoaaMZ"
      },
      "outputs": [],
      "source": [
        "#pred = token_classifier(\"Mujer de 74 años que ingresó en el hospital por obnubilación y anuria tras presentar durante 5 días dolor abdominal y vómitos.\")\n",
        "pred = token_classifier(\"Entre sus antecedentes destacaba una DM tratada con metformina (850 mg/8 h) y glibenclamida.\")\n",
        "#pred = token_classifier(\"Anamnesis\\nPresentamos el caso de un varón de 69 años de edad con antecedentes de ángor estable desde hace más de un año, remitido desde Atención Primaria por síntomas de tracto urinario inferior. El paciente presenta una puntuación de síntomas prostáticos (IPSS) de 9; refiere erección satisfactoria, con test de la disfunción eréctil (IIEF-5) de 23.\\n\\nExploración física\\nComplexión corporal normal, con un índice de masa corporal de 20. Al tacto rectal se palpa una próstata sin hallazgos patológicos de interés.\\n\\nPruebas complementarias\\n• A nivel analítico se evidencia un antígeno prostático específico (PSA) de 7,22 con cociente PSA libre/PSA total de 0,19.\\n• En la ecografía transrectal se aprecia una próstata de 44 g.\\n• Se realiza una biopsia transrectal ecodirigida de próstata, con resultado de adenocarcinoma de próstata Gleason 6 (3 + 3) en el lóbulo derecho.\\n\\nTratamiento y evolución\\nTras ofrecer las distintas opciones de tratamiento, el paciente opta por prostatectomía radical robótica. Se realiza un abordaje intraperitoneal con movilización vesical para acceder al espacio de Retzius. Tras la liberación de la grasa periprostática y la apertura de la fascia endopélvica se advierte la presencia de arterias pudendas accesorias (APA) bilaterales. Ambas APA transcurren en íntima relación con la cápsula prostática, siendo necesaria una disección minuciosa para su conservación.\\nTras identificar el cuello vesical, se procede a su sección para acceder al espacio retroprostático. Se disecan y liberan los conductos deferentes y vesículas seminales. A continuación se procede a una disección interfascial bilateral de bandeletas neurovasculares para su preservación. Tras la sección de los ligamentos puboprostáticos y del plexo de Santorini se secciona la uretra. Una vez preservadas ambas APA se procede a la anastomosis vesicouretral con sutura de monofilamento reabsorbible según la técnica de Van Velthoven. Por último, se procede al llenado de la vejiga para comprobar la estanqueidad de la sutura. Sangrado aproximado intraoperatorio de 300 ml, tiempo de consola 120 minutos.\\nEn las revisiones ulteriores el paciente recupera de forma progresiva la función eréctil, consiguiendo en la última revisión al año un IIEF de 17. El valor del PSA en la última revisión se mantiene en 0,00.\\n\")\n",
        "#pred = token_classifier(\"El segundo caso que se presenta es el de una lactante de 2 meses que acudió a urgencias por febrícula y un cuadro de urticaria aguda, aparentemente pruriginoso, de 4 días de evolución. Inicialmente afectaba la cara y las extremidades superiores, extendiéndose en pocas horas al tronco y las extremidades inferiores. Exantema urticariforme. No había afectación palmoplantar. Estas manifestaciones no se acompañaban de angioedema acral, labial ni lingual.\\n\\nComo antecedente epidemiológico destacable, la paciente convivía con 2 personas con COVID-19 demostrada, por lo que se realizó PCR a SARS-CoV-2 en aspirado nasofaríngeo, que fue positiva. Se pautó tratamiento sintomático vía oral con buena respuesta. La duración de la mayoría de las lesiones fue inferior a 24h, resolviéndose la clínica cutánea en 5 días, sin otras manifestaciones asociadas.\")\n",
        "#pred = token_classifier(\"Mujer de 74 años que ingresó en el hospital por obnubilación y anuria tras presentar durante 5 días dolor abdominal y vómitos. Entre sus antecedentes destacaba una DM tratada con metformina (850 mg/8 h) y glibenclamida. La presión arterial era de 105/60 mmHg, la frecuencia cardíaca de 155 latidos/minuto y la temperatura de 36,7º C. En la exploración destacaba deshidratación intensa, desorientación, respiración de Kussmaul, dolor abdominal con peristaltismo débil y ausencia de defensa abdominal. La tabla 2 muestra los principales datos analíticos, destacando además una hiperamilasemia de 2.605 U/l. Una tomografía computarizada abdominal descubrió un aumento del tamaño de la cabeza del páncreas sugerente de pancreatitis aguda. Tras suspender la administración de metformina, la paciente fue intubada orotraquealmente y conectada a un respirador mecánico. También recibió tratamiento a base de fluidos con suplementos de potasio, noradrenalina, bicarbonato, insulina, amiodarona, imipenen y furosemida. Al segundo día de ingreso, tras administrar 750 mEq de bicarbonato y 140 mEq de potasio, se normalizó el equilibrio ácido-básico (pH 7,41 y bicarbonato 20 mEq/l) e hidroelectrolítico (sodio 147 mEq/l, potasio 3,5 mEq/l) y la creatinina descendió a 5,5 mg/dl. Al tercer día de ingreso, por la presencia de deposiciones mucosas repetidas, se realizó una colonoscopia que puso de manifiesto una formación polipoidea sésil situada junto al esfínter anal y de 14 cm de longitud. La muestra endoscópica fue informada como adenoma velloso de recto. Al séptimo día de ingreso la enferma fue extubada, y dos días más tarde fue trasladada a planta para extirpación del adenoma\")\n",
        "#pred = token_classifier(\"Hombre de 38 años. Ingresó a la UCI (14/IX/ 2000), en postquirúrgico inmediato por heridas múltiples por arma de fuego en miembro superior derecho y abdomen. Hemicolectomía derecha con anastomosis termino-terminal y drenaje de hemoperitoneo (2000 cc.). Trece horas después, fue reintervenido por hipotensión y anemia, drenándose un hemoperitoneo de 3.000 cc. Bajo la sospecha de coagulopatía se realizó 48 horas de empaquetamiento y posteriormente malla de Velcro. El paciente presentó acidosis metabólica, insuficiencia renal aguda (el día 17, en remisión el 18) y coagulación intravascular diseminada.Fiebre el 17, 18 y 19. El 19 se llevó a un lavado abdominal (cierre fallido). Requirió ventilación mecánica desde el postquirúrgico hasta el 18 y se reinició el 19.Paraclínicos: Sep 17: Hb 7.8 gm/dl. Sep 18: leucocitos: 6.600, hipomagnesemia. Sep 19: hipofosfatemia (0.9 meq/lt). Sep 20: creatinina normal, hipofosfatemia.Medicación: Sep 18: Suspendida sedación (se inició en el postquirúrgico), recibe Ranitidinay Morfina. Septiembre 19: suspenden Morfina, reinician sedación bajo ventilación mecánica. Corrección de hipofosfatemia.\\n\\nDescripción y tratamiento de las alteraciones del comportamiento\\n18 de septiembre: obedece órdenes sencillas. Presentó agitación leve, poca colaboración yconfusión. Se le diagnosticó un delirium para el cual se le formulo Haloperidol, la primeradosis se le suministró a las 17:00 horas 1 mg. I.V. y luego se repitió cada 8 horas.Septiembre 19: igual dosis de Haloperidol.Sep 20: fue desintubado con agitación motora severa y confuso, se aumentó la dosis deHaloperidol a 2 mg c/8 horas I.V. Al no haber control de la alteración se incrementó elHaloperidol a 3 mg cada 4 horas junto con Midazolam 2mg (5 bolos). Ante la no mejoríase le administró Fenergan 50mg I.M. e infusión de Haloperidol 2mg/cada hora. Ante lasituación se hizo IC a Psiquiatría de Enlace.El psiquiatra encontró que tenía una historia de consumo de alcohol semanal. Personalidadprevia: ansioso, íaceleradoî, sin antecedentes claros de otra enfermedad diferente a abusode alcohol. Los informantes eran poco confiables porque no vivían continuamente con él(exesposa e hija). En esa fecha los datos positivos del exámen mental fueron los siguientes: inquietud, con evidencia de alucinaciones visuales, desorientación parcial en persona, lugar, tiempo y enfermedad; inmovilizado.Se diagnóstica delirium y se comienza a descartar un sindrome de abstinencia a alcohol uotros psicotóxicos. Se continuó el tratamiento con Haloperidol 10 mg I.V. cada 20 minutos,hasta alcanzar un total de 80mg. Se solicitó tomografía cerebral informada normal; se hizocorrección de electrolitos (hiponatremia: 138); las pruebas hepáticas fueron normales. Comola agitación persistía, se incrementó el Haloperidol hasta 180 mg junto con 5 bolos de 2 mgde Midazolam. Como no se logró controlar la agitación, se le suministró infusión de PROPOFOL (anestésico endovenoso) 120 mg, logrando control del cuadro clínico.Septiembre 21: disnea con infiltrado alveolar. Hipomagnesemia. En el liquido peritoneal seencontró Serratia Marcenses y Stafilococo Aureus. Delirium mejor: orientado en todas lasáreas. Refiere consumo de una botella semanal de alcohol.Se continuó con 90 mg. I.V. díarios de Haloperidol (15 mg cada 4 horas), Loracepam 1mgcada 6 horas V.O. Se suspende ranitidina porque puede agravar el delirium.Septiembre 22: se disminuye Haloperidol 10 mg c/4 horas I.V. El cultivo del líquido peritoneal positivo con resistencia a Cefotaxime, se inicia Ciprofloxacina, Vancomicina. Teníainfiltrados alveolares, fiebre, derrame pleural. Exámen mental: orientado, describe el trauma, refiere dificultades para tolerar la frustración, se considera como diagnóstico un posible Trastorno de la Personalidad. Se suspende Haloperidol y se deja Lorazepam 1 mgcada 12 horas, vía oral.Septiembre 23: sale de la UCI a habitación corriente.Septiembre 25: informa que es consumidor habitual de alcohol y cocaína. Se autoriza salida de la institución\")\n",
        "#pred = token_classifier(\"Niña de 4 años, sin antecedentes de interés, que consulta por tumefacción cervical izquierda dolorosa y fiebre (38oC), de pocas horas de evolución. El día anterior, tras quejarse de dolor a nivel occipital, lo padres observaron una garrapata en cuero cabelludo que retiraron manualmente. Tres días antes, la niña había estado en una zona rural en contacto con animales.\\n\\nEn la exploración física, se observa sobre la zona de picadura de la garrapata, en región parietoccipital izquierda, una placa eritematosa de 1 cm de diámetro con escara central, tumefacción cervical ipsilateral dolorosa, sin exantemas, siendo el resto de exploración normal. Placa de 1 cm de diámetro, con escara necrótica central tras picadura de garrapata.\\n\\nSe realiza hemograma y bioquímica con resultado normal, sin elevación de reactantes de fase aguda, y ecografía cervical, que muestra adenopatías de características inflamatorias, de predominio en región laterocervical izquierda, no abcesificadas, siendo la mayor de 3,2 x 1,2 cm. Ecografía cervical. Adenopatía de 3,2 x 1,2 cm, de características inflamatorias y no abcesificada.\\n\\nEvolución\\nSe sospechó un cuadro de linfadenopatía transmitida por garrapata o TIBOLA (de su acrónimo inglés Tick-Borne Lymphadenopathy). Se pautó tratamiento con doxiciclina oral (5 mg/kg/día cada 12 horas) en una pauta corta de 2 días. Paciente quedo afebril en las primeras 24 horas, con disminución progresiva de la adenitis cervical hasta quedar asintomáticas. Se realizó serología al diagnóstico y a las 6 semanas frente a Rickettsia conorii y Borrelia burdorferi (únicas serologías disponibles en nuestra área) con resultado negativo.\\n\\nDentro de las numerosas zoonosis cuyo vector es la garrapata, es importante conocer las manifestaciones de aquellas que son más frecuentes en nuestro país. Entre estas, destaca la linfadenopatía transmitida por garrapata o TIBOLA. Esta entidad se engloba dentro del grupo de enfermedades conocidas como Fiebres Manchadas ocasionadas por bacterias del genero Rickettsia (cocobacilos gram negativos intracelulares) y transmitidas por garrapatas. El agente principal aislado, en estos casos, es la Rickettsia slovaca, si bien, se han aislado otros patógenos, como Rickettsia raoultii, Rickettsia riojay otras bacterias, en pacientes con la misma clínica. Los vectores son las garrapatas del género Dermacentor (Dermacentor marginatusen los países mediterráneos, y Dermacentor reticularis en el Centro y Este de Europa). En los últimos años, TIBOLA, que también se conoce como DEBONEL (Dermacentor-borne necrosis erythema Lymphadenopathy) o SENLAT (Scalp eschar with neck lymphadenopathy after a tick bite), tiene una incidencia mayor que la fiebre botonosa mediterránea (FBM); rickettsiosis, con la que se establece el principal diagnóstico diferencial de TIBOLA.\")\n",
        "#pred = token_classifier(\"La madre del paciente neonatal es una mujer embarazada de 34 años que vive cerca del mercado mayorista de marisco de Huanan (a unos 1,2 km de distancia), en Wuhan. No ha visitado el mercado durante su embarazo y su familia no tiene casos confirmados ni presuntos de COVID-19, pero en la misma comunidad en la que vive se han diagnosticado más de 15 personas. Tiene antecedentes de hipotiroidismo de 4 años de evolución y se ha tratado con fármacos por vía oral; no tiene antecedentes de hipertensión, diabetes ni cardiopatías. Tuvo un aborto en 2016 a causa de alteraciones cromosómicas. Es alérgica a la penicilina y a las cefalosporinas de primera generación (positivo en pruebas cutáneas).\\n\\nA las 20:00 h del 1 de febrero de 2020, la mujer, de 40 semanas de gestación, presentó una pequeña hemorragia vaginal y dolor en la región abdominal inferior. Dos horas después, presentó fiebre (37,8 °C) y acudió al centro de asistencia maternoinfantil de Wuhan. Como tenía fiebre, fue derivada al consultorio de enfermedades infecciosas del hospital Tongji de Wuhan a la mañana siguiente. Una TAC torácica mostró opacidades de vidrio esmerilado en los lóbulos superior e inferior izquierdos, lo que indicaba la posibilidad de neumonía vírica.\\n\\nTAC torácica de la madre, obtenida el 2 de febrero de 2020, que muestra signos de infección en los lóbulos inferior y superior izquierdos e indica la posibilidad de neumonía vírica, con enfisema reducido en el lóbulo inferior derecho y una pequeña afectación en el lóbulo medio derecho.\\n\\nLos análisis de sangre mostraron linfocitopenia (0,97 × 109 células/L [normal: 1,1–3,2 × 109 células/L]), neutrofilia (9,97 × 109 células/L [normal: 1,8–6,3 × 109 células/L]) y concentraciones altas de proteína C-reactiva (11,5 mg/L [normal: < 1 mg/L]). Se decidió hospitalizarla por presunta neumonía vírica.\\n\\nAl ingreso, su temperatura era de 37,8 °C, la presión arterial de 131/89 mmHg, la frecuencia respiratoria de 20 r.p.m. y el pulso de 96 l.p.m. No presentaba tos ni expectoración. El pulso fetal era de 136 l.p.m. y su registro no mostró anomalías. Se realizó una cesárea de urgencia. Intraoperatoriamente se observó líquido amniótico con meconio. A las 8:45 la paciente dio a luz un niño con un peso de 3025 g. Los índices de Apgar a 1 y 5 minutos fueron de 8 y 9, respectivamente. El niño no regurgitó tras el parto. La piel era rojiza y el lloro, alto. La madre llevó una mascarilla N95 durante la intervención y, tras el alumbramiento, el niño no tuvo contacto con la madre. El niño se transfirió a la planta de neonatología 10 minutos después del parto para estrecha vigilancia; la madre se transfirió a la planta de enfermedades infecciosas para su aislamiento tras la intervención.\\n\\nMedia hora después del parto, el niño vomitó una vez tras ser alimentado con leche artificial, y se consideró que tenía disfagia. Tras un lavado gástrico, el niño pudo ser alimentado sin complicaciones. Los análisis de sangre del recién nacido mostraron linfocitopenia (2,43 × 109 células/L [normal: 3–8 × 109 células/L]), pruebas funcionales hepáticas alteradas (aspartato-aminotransferasa 143 U/L [normal: ≤  41 U/L]; bilirrubina total 33,0 μmol/L [normal: ≤ 26 μmol/L]; bilirrubina indirecta 26,0 μmol/L [normal: ≤ 16,8 μmol/L]) y alta concentración de creatina-cinasa (479 U/L [normal: ≤  41 U/L]). Se administró penicilina G (150.000 U una vez por día, bolo intravenoso) y vitamina K1 (1 mg una vez por día, i.v.) como profilaxis antibiótica y para evitar coagulopatías, respectivamente.\\n\\nLa madre permaneció en buen estado y afebril durante el periodo posoperatorio inmediato. No presentó tos ni ninguna otra molestia, como diarrea, náuseas o vómitos. Sus constantes vitales fueron estables, con una saturación de oxígeno del 99%. Se le administró un tratamiento antivírico, con 40 μg de interferón α1b humano recombinante atomizado por vía inhalatoria con 2 mL de solución de esterilización dos veces por día y ganciclovir (0,25 g cada 12 horas, i.v.). También se le administró abipenem (0,3 g cada 12 horas, i.v.) y moxifloxacina (0,4 g una vez por día, i.v.) para prevenir infecciones. La madre tuvo fiebre intermitente durante el primer día del posoperatorio, llegando a 38,3 °C; se le administró metilprednisolona (20 mg i.v.). Su frotis faríngeo para detección del SARS-CoV-2 resultó positivo ese mismo día. Inmediatamente, se obtuvo un frotis faríngeo del recién nacido (36 horas tras el parto) junto con leche de la madre. Recomendamos a la madre no amamantar al niño y extraerse leche para evitar mastitis.\\n\\nLa respuesta neurológica del recién nacido resultó aceptable durante el primer día después del parto y su saturación de oxígeno se mantuvo > 92% sin oxigenoterapia. Las pruebas analíticas del niño fueron negativas para Legionella pneumophila, Chlamydia pneumoniae, Mycoplasma pneumoniae, Rickettsia, adenovirus, virus respiratorio sincicial, virus de la gripe A virus de la gripe B y virus paragripal 1–3.\\n\\nEl 4 de febrero, el segundo día posoperatorio, las constantes vitales de la madre eran estables y se le administró prednisolona (40 mg una vez por día i.v.). El recién nacido se mantuvo sano y su gasometría mostró pH de 7,476↑, presión parcial de dióxido de carbono de 28,2 mm Hg↓, presión parcial de oxígeno de 116,0 mm Hg↑, bicarbonato de 20,6 mmol/L↓, exceso de base de 1,30 mmol/L y saturación de oxígeno periférico de 98,4%. Las pruebas para un conjunto de virus pediátricos resultaron negativas para citomegalovirus, virus de la rubéola, Toxoplasma gondii, virus del herpes común tipos 1 y 2, ecovirus, parvovirus B19, virus de Epstein-Barr, virus de Coxsackie A16, virus de Coxsackie B, virus del sarampión y virus de la varicela zóster. La TAC torácica del recién nacido mostró un engrosamiento de la textura de los pulmones sin anormalidades cardíacas. TAC torácica del recién nacido, obtenida el 4 de febrero de 2020, que muestra un engrosamiento de la textura de los pulmones sin anormalidades cardíacas. Se alimentó al niño con leche artificial, 25 mL cada 3 horas, y se supervisó estrechamente.\\n\\nEl 5 de febrero, las constantes vitales del recién nacido eran estables, con una saturación de oxígeno por encima del 90% y sin molestias como apnea o vómitos. El resultado del frotis faríngeo para detección del SARS-CoV-2 fue positivo a las 36 horas después del parto. Combinando todas las pruebas analíticas y un intercambio exhaustivo de ideas, diagnosticamos que el niño presentaba infección por SARS-CoV-2. Como el departamento neonatal del Hospital Tingji no dispone de las condiciones de aislamiento para el recién nacido, se transfirió al Hospital Maternoinfantil de Wuhan ese mismo día, para un mejor aislamiento. Tras hallar las pruebas de la infección neonatal, efectuamos pruebas de ácido nucleico del SARS-CoV-2 en la sangre del cordón umbilical y muestras de la placenta que habíamos conservado durante la intervención; los resultados fueron negativos. La muestra de la leche materna también fue negativa para SARS-CoV-2.\\n\\nHicimos un seguimiento del estado del recién nacido después de ser transferido al Hospital Maternoinfantil de Wuhan. Su estado era bueno y afebril, sin tos ni vómitos. Fue supervisado estrechamente en condiciones de aislamiento y no se le administró ningún tratamiento especial. Una TAC torácica el 6 de febrero mostró sombras nodulares de alta densidad bajo la pleura del segmento posterior del lóbulo superior del pulmón derecho. En una TAC torácica del 12 de febrero se observaron pequeños núcleos de sombras parcheadas en los lóbulos inferior y superior del pulmón derecho. En una TAC torácica del 17 de febrero se observaron unos pocos y pequeños núcleos de sombras parcheadas en los lóbulos inferior y superior del pulmón derecho, absorbidas en comparación con las anteriores. El 17 de febrero de 2020, las pruebas de ácido nucleico de frotis faríngeos y anales para detección del SARS-CoV-2 resultaron negativas. El recién nacido fue dado de alta el 18 de febrero de 2020.\\n\")\n",
        "#pred = token_classifier(\"Mujer de 78 años, diagnosticada en 1978 de SSP por un síndrome seco (xerostomía y xeroftalmia), con biopsia de glándula salivar menor y pruebas de Schirmer y Rosa Bengala positivas.\")\n",
        "#pred = token_classifier(\"Paciente mujer de 84 años diagnosticada de artritis reumatoide, que ingresó de urgencia por dolor y distensión abdominal. Con el diagnóstico de íleo suboclusivo se instauró inicialmente tratamiento médico. Sin ningún antecedente urológico, comenzó a las pocas horas del sondaje uretral con hematuria, que se hizo muy intensa, evolucionando a la formación de un gran coágulo vesical que ocupaba toda la cavidad, observando además en la tomografía axial computarizada líquido y gas perivesical. Se procedió a intervención quirúrgica urgente, observando un tramo de íleon de 1,5 m de longitud hasta 10 cm de la válvula ileocecal, de aspecto violáceo edematoso, la cual se recupera adquiriendo aspecto, coloración y peristaltismo normales; presentaba una pequeña fisura en la pared vesical, por lo que se le practicó una cistotomía con la que se drena el gran coágulo, observando sangrado en sábana de la pared y gran friabilidad de la misma, tomando biopsias múltiples y realizando posteriormente ligadura de ambas hipogástricas. En el postoperatorio inmediato, tras un cuadro de anuria y alteración hemodinámica severa, llegó al exitus (09/05/2000). El diagnóstico anatomopatológico reveló que todas las biopsias vesicales que fueron practicadas tenían depósito amiloide (AA) vascular e intersticial.\")\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL4mdo1umfTJ"
      },
      "outputs": [],
      "source": [
        "test_path = \"/content/drive/MyDrive/Datasets/test_background/text_files/distemist_test_\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF2yE2iJtAJy"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "with open(test_path + str(i) + \".txt\", \"r\", encoding=\"UTF-8\") as ftest:\n",
        "  pred = token_classifier(ftest.read())\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-Processing"
      ],
      "metadata": {
        "id": "5SXdOl-E6Qk6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blQLws4pLuBP"
      },
      "outputs": [],
      "source": [
        "def grouping_entities(pred):\n",
        "  import re\n",
        "  output = []\n",
        "  for e in pred:\n",
        "    if \"##\" not in e['word']:\n",
        "      output.append(e)\n",
        "    else:\n",
        "      try:\n",
        "        if e['start'] == (output[-1]['end']):\n",
        "          output[-1]['word'] = output[-1]['word']+re.sub(\"##\",\"\",e['word'])\n",
        "          output[-1]['end'] = e['end']\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "      if (e['entity_group'] == \"B\" or e['entity_group'] == \"I\") and (e['start'] == (output[-2]['end']+1)):\n",
        "        output[-2]['word'] = output[-2]['word']+\" \"+e['word']\n",
        "        output[-2]['end'] = e['end']\n",
        "        output.pop(-1)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    try:\n",
        "      if e['start'] == (output[-2]['end']):\n",
        "        output[-2]['word'] = output[-2]['word']+e['word']\n",
        "        output[-2]['end'] = e['end']\n",
        "        output.pop(-1)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hPi30NgqtDQ"
      },
      "outputs": [],
      "source": [
        "grouping_entities(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZwOFHailsVL"
      },
      "source": [
        "## Predictions on test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D_RSE3ulwJw"
      },
      "outputs": [],
      "source": [
        "print(\"Processing...\")\n",
        "import re\n",
        "f = open(\"/content/drive/MyDrive/distemist_subtrack1_test_predictions_NER_EHR_Spanish_model_Mulitlingual_BERT.tsv\", \"w\", encoding=\"UTF-8\")\n",
        "#f.write(\"filename\\tmark\\tlabel\\toff0\\toff1\\tspan\\n\")\n",
        "f.write(\"filename\\tlabel\\toff0\\toff1\\tspan\\n\")\n",
        "for i in range(1,3001):\n",
        "  print(f\"Text: {i}\", end=\"\\r\")\n",
        "  with open(test_path + str(i) + \".txt\", \"r\", encoding=\"UTF-8\") as ftest:\n",
        "    hc = ftest.read()\n",
        "    pred = token_classifier(hc)\n",
        "    pred_grouped = grouping_entities(pred)\n",
        "    t = 1\n",
        "    for p in pred_grouped:\n",
        "\n",
        "      off0 = int(p['start'])\n",
        "      off1 = int(p['end'])\n",
        "      span = hc[off0:off1]\n",
        "\n",
        "      if span in [\".\", \",\", \";\", \":\", '\"', \"-\", \"a\", \"de\", \"por\", \"in\", \"que\", \"da\", \"di\", \"se\", \"Las\", \"re\", \"sin\"]:\n",
        "        continue\n",
        "\n",
        "      if \"\\n\" in span:\n",
        "        span = re.sub(\"\\n\",\" \",span)\n",
        "\n",
        "      if \" - \" in span:\n",
        "        span = re.sub(\" - \",\"-\",span)\n",
        "        off1 = off1-2\n",
        "\n",
        "      if \"( \" in span:\n",
        "        span = re.sub(\"\\( \",\"(\",span)\n",
        "        off1 = off1-1\n",
        "\n",
        "      if \" )\" in span:\n",
        "        span = re.sub(\" \\)\",\")\",span)\n",
        "        off1 = off1-1\n",
        "\n",
        "      if span.endswith(\" y\") :\n",
        "        span = span[:-2]\n",
        "        off1 = off1-2\n",
        "\n",
        "      if span.endswith(\" de\") or span.endswith(\" en\"):\n",
        "        span = span[:-3]\n",
        "        off1 = off1-3\n",
        "\n",
        "      if span.endswith(\" por\") or span.endswith(\" con\"):\n",
        "        span = span[:-4]\n",
        "        off1 = off1-4\n",
        "\n",
        "      if span.endswith(\".\") or span.endswith(\",\") or span.endswith(\";\") or span.endswith(\":\") or span.endswith(\"–\") or span.endswith(\"-\"):\n",
        "        span = span[:-1]\n",
        "        off1 = off1-1\n",
        "\n",
        "      if span.endswith(\" .\") or span.endswith(\" ,\") or span.endswith(\" ;\") or span.endswith(\" :\") or span.endswith(\" –\") or span.endswith(\" -\"):\n",
        "        span = span[:-2]\n",
        "        off1 = off1-2\n",
        "\n",
        "      #f.write(\"distemist_test_\"+str(i)+\"\\t\"+\"T\"+str(t)+\"\\t\"+\"ENFERMEDAD\"+\"\\t\"+str(p['start'])+\"\\t\"+str(p['end'])+\"\\t\"+p['word']+\"\\n\")\n",
        "      #f.write(\"distemist_test_\"+str(i)+\"\\t\"+\"T\"+str(t)+\"\\t\"+\"ENFERMEDAD\"+\"\\t\"+str(off0)+\"\\t\"+str(off1)+\"\\t\"+span+\"\\n\")\n",
        "      f.write(\"distemist_test_\"+str(i)+\"\\t\"+\"ENFERMEDAD\"+\"\\t\"+str(off0)+\"\\t\"+str(off1)+\"\\t\"+span+\"\\n\")\n",
        "      #print(\"distemist_test_\"+str(i)+\"\\t\"+\"T\"+str(t)+\"\\t\"+\"ENFERMEDAD\"+\"\\t\"+str(p['start'])+\"\\t\"+str(p['end'])+\"\\t\"+p['word'])\n",
        "      t+=1\n",
        "f.close()\n",
        "print(\"Completo.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}